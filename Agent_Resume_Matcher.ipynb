{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "4f7a981c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "4f7a981c",
        "outputId": "2568f6c6-12a9-44ba-f1e5-fe21f85dc76e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: langchain-openai in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (1.1.7)\n",
            "Requirement already satisfied: langchain-community in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (0.4.1)\n",
            "Requirement already satisfied: langchain-text-splitters in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (1.1.0)\n",
            "Requirement already satisfied: langchain-core in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (1.2.7)\n",
            "Requirement already satisfied: faiss-cpu in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (1.13.2)\n",
            "Requirement already satisfied: python-dotenv in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (1.2.1)\n",
            "Requirement already satisfied: pypdf in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (6.5.0)\n",
            "Requirement already satisfied: langsmith in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (0.5.0)\n",
            "Requirement already satisfied: openai<3.0.0,>=1.109.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from langchain-openai) (2.14.0)\n",
            "Requirement already satisfied: tiktoken<1.0.0,>=0.7.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from langchain-openai) (0.12.0)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from langchain-core) (1.33)\n",
            "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from langchain-core) (25.0)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from langchain-core) (2.12.5)\n",
            "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from langchain-core) (6.0.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from langchain-core) (9.1.2)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from langchain-core) (4.15.0)\n",
            "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from langchain-core) (0.12.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from langsmith) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from langsmith) (3.11.5)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from langsmith) (1.0.0)\n",
            "Requirement already satisfied: requests>=2.0.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from langsmith) (2.32.5)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from langsmith) (0.25.0)\n",
            "Requirement already satisfied: anyio in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from httpx<1,>=0.23.0->langsmith) (4.12.0)\n",
            "Requirement already satisfied: certifi in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from httpx<1,>=0.23.0->langsmith) (2025.11.12)\n",
            "Requirement already satisfied: httpcore==1.* in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from httpx<1,>=0.23.0->langsmith) (1.0.9)\n",
            "Requirement already satisfied: idna in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from httpx<1,>=0.23.0->langsmith) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core) (3.0.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.10.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (0.12.0)\n",
            "Requirement already satisfied: sniffio in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (4.67.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.5 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core) (2.41.5)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core) (0.4.2)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from tiktoken<1.0.0,>=0.7.0->langchain-openai) (2025.11.3)\n",
            "Requirement already satisfied: langchain-classic<2.0.0,>=1.0.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from langchain-community) (1.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3.0.0,>=1.4.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from langchain-community) (2.0.45)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from langchain-community) (3.13.2)\n",
            "Requirement already satisfied: dataclasses-json<0.7.0,>=0.6.7 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from langchain-community) (0.6.7)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from langchain-community) (2.12.0)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from langchain-community) (0.4.3)\n",
            "Requirement already satisfied: numpy>=2.1.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from langchain-community) (2.4.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.22.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community) (3.26.2)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community) (0.9.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from requests>=2.0.0->langsmith) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from requests>=2.0.0->langsmith) (2.6.2)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain-community) (1.1.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install langchain-openai langchain-community langchain-text-splitters langchain-core faiss-cpu python-dotenv pypdf langchain-openai langsmith"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "faf9e212",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "faf9e212",
        "outputId": "8dae7b19-013e-4fca-d283-b8a872a1ec6a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úì Setup complete\n",
            "API Key: sk-proj-2D_k1B8OV3MW...\n",
            "‚úì Folders created: ./resumes and ./resume_db\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import shutil\n",
        "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from langchain_community.document_loaders import TextLoader, DirectoryLoader, PyPDFLoader\n",
        "from dotenv import load_dotenv\n",
        "# from google.colab import userdata\n",
        "\n",
        "# Load API key\n",
        "# os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')\n",
        "load_dotenv()\n",
        "print(\"‚úì Setup complete\")\n",
        "print(\"API Key:\", os.environ.get(\"OPENAI_API_KEY\", \"Not set\")[:20] + \"...\")\n",
        "\n",
        "# Create folders if they don't exist\n",
        "os.makedirs(\"./resumes\", exist_ok=True)\n",
        "os.makedirs(\"./resume_db\", exist_ok=True)\n",
        "print(\"‚úì Folders created: ./resumes and ./resume_db\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a0eb34f5",
      "metadata": {
        "id": "a0eb34f5"
      },
      "source": [
        "### 1. Define your functions as LangChain Tools\n",
        "\n",
        "LangChain's `@tool` decorator allows you to expose Python functions to an LLM agent. The docstring of the function is crucial as the agent uses it to understand what the tool does and what arguments it expects."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "112f54c3",
      "metadata": {
        "id": "112f54c3"
      },
      "outputs": [],
      "source": [
        "from langchain.tools import tool\n",
        "\n",
        "# Wrap the existing functions as tools\n",
        "\n",
        "@tool\n",
        "def ingest_resumes_tool():\n",
        "    \"\"\"Ingest new resumes from the './resumes' folder into the vector database. Use this tool when new resumes need to be processed or the database needs to be updated.\"\"\"\n",
        "    return ingest_resumes()\n",
        "\n",
        "@tool\n",
        "def list_resumes_tool():\n",
        "    \"\"\"List all the unique resume file names currently stored in the vector database. Use this tool to see what resumes have been ingested.\"\"\"\n",
        "    return list_resumes()\n",
        "\n",
        "@tool\n",
        "def search_resumes_tool(skills: str):\n",
        "    \"\"\"Search for candidates whose resumes match the given skills. Input should be a comma-separated string of required skills (e.g., 'Python, Machine Learning, Docker'). Use this tool to find candidates for a job opening.\"\"\"\n",
        "    return search_resumes(skills)\n",
        "\n",
        "@tool\n",
        "def clear_resumes_tool():\n",
        "    \"\"\"Clear all resumes from the vector database. This will delete the entire resume database. Use this tool to start fresh or remove all stored resume data.\"\"\"\n",
        "    return clear_resumes()\n",
        "\n",
        "# Note: generate_resume and save_resume are not included as direct agent tools here\n",
        "# because they typically involve structured input (dictionaries) that are harder for a generic agent to construct directly from natural language.\n",
        "# However, you could create a more complex tool that takes simpler inputs and then constructs the dictionary internally.\n",
        "\n",
        "\n",
        "# Create a list of all available tools\n",
        "tools = [\n",
        "    ingest_resumes_tool,\n",
        "    list_resumes_tool,\n",
        "    search_resumes_tool,\n",
        "    clear_resumes_tool\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "080becf9",
      "metadata": {
        "id": "080becf9"
      },
      "source": [
        "### 2. Set up the LangChain Agent\n",
        "\n",
        "Now, you'll need an LLM to act as the agent's 'brain' and an `AgentExecutor` to run the agent with the defined tools."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "f79043b7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 378
        },
        "id": "f79043b7",
        "outputId": "3c2dbb70-3c0d-4914-d5a6-665c5e067392"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úì Agent and tools set up successfully.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import shutil\n",
        "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
        "from langchain_core.tools import tool\n",
        "from langchain_core.messages import HumanMessage\n",
        "from langchain.agents import create_agent\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from langchain_community.document_loaders import TextLoader, DirectoryLoader, PyPDFLoader\n",
        "\n",
        "# Initialize embeddings globally\n",
        "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
        "\n",
        "# Define the actual resume management functions\n",
        "\n",
        "def ingest_resumes():\n",
        "    \"\"\"Load resumes from ./resumes folder and add to vector database\"\"\"\n",
        "    print(\"üì• Ingesting resumes...\")\n",
        "    # Load text files\n",
        "    txt_loader = DirectoryLoader(\"./resumes\", glob=\"**/*.txt\", loader_cls=TextLoader)\n",
        "    txt_docs = txt_loader.load()\n",
        "    # Load PDF files\n",
        "    pdf_loader = DirectoryLoader(\"./resumes\", glob=\"**/*.pdf\", loader_cls=PyPDFLoader)\n",
        "    pdf_docs = pdf_loader.load()\n",
        "    all_docs = txt_docs + pdf_docs\n",
        "    \n",
        "    if not all_docs:\n",
        "        print(\"‚ùå No resumes found in ./resumes folder\")\n",
        "        return \"No resumes found in ./resumes folder\"\n",
        "    \n",
        "    # Split documents into chunks\n",
        "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
        "    chunks = text_splitter.split_documents(all_docs)\n",
        "    \n",
        "    # Check if FAISS index file exists (not just folder)\n",
        "    db_file_exists = os.path.exists(\"./resume_db/index.faiss\")\n",
        "    \n",
        "    if db_file_exists:\n",
        "        # Load existing and add new documents\n",
        "        vectorstore = FAISS.load_local(\"./resume_db\", embeddings, allow_dangerous_deserialization=True)\n",
        "        vectorstore.add_documents(chunks)\n",
        "        print(f\"‚úì Added {len(chunks)} chunks from {len(all_docs)} resumes\")\n",
        "        result = f\"Added {len(chunks)} chunks from {len(all_docs)} resumes to existing database\"\n",
        "    else:\n",
        "        # Create new vector store\n",
        "        vectorstore = FAISS.from_documents(chunks, embeddings)\n",
        "        print(f\"‚úì Created new database with {len(chunks)} chunks from {len(all_docs)} resumes\")\n",
        "        result = f\"Created new database with {len(chunks)} chunks from {len(all_docs)} resumes\"\n",
        "    \n",
        "    vectorstore.save_local(\"./resume_db\")\n",
        "    print(\"‚úì Database saved successfully\")\n",
        "    return result\n",
        "\n",
        "def list_resumes():\n",
        "    \"\"\"List all resumes stored in vector database\"\"\"\n",
        "    print(\"üìã Listing resumes...\")\n",
        "    if not os.path.exists(\"./resume_db/index.faiss\"):\n",
        "        print(\"‚ùå No database found. Please ingest resumes first.\")\n",
        "        return \"No database found. Please ingest resumes first.\"\n",
        "    \n",
        "    vectorstore = FAISS.load_local(\"./resume_db\", embeddings, allow_dangerous_deserialization=True)\n",
        "    # Get all documents\n",
        "    all_docs = vectorstore.docstore._dict\n",
        "    \n",
        "    # Extract unique sources\n",
        "    sources = set()\n",
        "    for doc in all_docs.values():\n",
        "        if hasattr(doc, 'metadata') and 'source' in doc.metadata:\n",
        "            sources.add(os.path.basename(doc.metadata['source']))\n",
        "    \n",
        "    result = f\"Found {len(sources)} resumes in database:\\n\"\n",
        "    for i, source in enumerate(sorted(sources), 1):\n",
        "        result += f\"{i}. {source}\\n\"\n",
        "        print(f\" {i}. {source}\")\n",
        "    \n",
        "    return result\n",
        "\n",
        "def search_resumes(skills):\n",
        "    \"\"\"Search resumes by skills and return best matches\"\"\"\n",
        "    print(f\"üîç Searching for candidates with skills: {skills}\")\n",
        "    if not os.path.exists(\"./resume_db/index.faiss\"):\n",
        "        print(\"‚ùå No database found. Please ingest resumes first.\")\n",
        "        return \"No database found. Please ingest resumes first.\"\n",
        "    \n",
        "    vectorstore = FAISS.load_local(\"./resume_db\", embeddings, allow_dangerous_deserialization=True)\n",
        "    \n",
        "    # Search for relevant resume chunks\n",
        "    retriever = vectorstore.as_retriever(search_kwargs={\"k\": 5})\n",
        "    docs = retriever.invoke(skills)\n",
        "    \n",
        "    # Create context from retrieved documents\n",
        "    context = \"\\n\\n\".join([f\"Resume {i+1}:\\n{doc.page_content}\" for i, doc in enumerate(docs)])\n",
        "    \n",
        "    # Create prompt for LLM\n",
        "    prompt = f\"\"\"You are a recruiter assistant. Based on the following resume excerpts, identify and rank the best candidates for the required skills.\n",
        "\n",
        "Required Skills: {skills}\n",
        "\n",
        "Resume Excerpts:\n",
        "{context}\n",
        "\n",
        "Please provide a quick summary for the top 3 best matching candidates. For each candidate, include their relevant skills, why they are a good fit, and a matching percentage. The response should be concise.\n",
        "\n",
        "Answer:\"\"\"\n",
        "    \n",
        "    # Get LLM response\n",
        "    llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
        "    response = llm.invoke(prompt)\n",
        "    \n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"üéØ SEARCH RESULTS\")\n",
        "    print(\"=\"*60)\n",
        "    print(response.content)\n",
        "    print(\"=\"*60)\n",
        "    \n",
        "    return response.content\n",
        "\n",
        "def clear_resumes():\n",
        "    \"\"\"Clear all resumes from vector database\"\"\"\n",
        "    print(\"üóëÔ∏è Clearing resume database...\")\n",
        "    if os.path.exists(\"./resume_db\"):\n",
        "        shutil.rmtree(\"./resume_db\")\n",
        "        print(\"‚úì Database cleared successfully\")\n",
        "        return \"Database cleared successfully\"\n",
        "    else:\n",
        "        print(\"‚ùå No database found\")\n",
        "        return \"No database found\"\n",
        "\n",
        "# Now wrap the functions as tools\n",
        "\n",
        "@tool\n",
        "def ingest_resumes_tool():\n",
        "    \"\"\"Ingest new resumes from the './resumes' folder into the vector database. Use this tool when new resumes need to be processed or the database needs to be updated.\"\"\"\n",
        "    return ingest_resumes()\n",
        "\n",
        "@tool\n",
        "def list_resumes_tool():\n",
        "    \"\"\"List all the unique resume file names currently stored in the vector database. Use this tool to see what resumes have been ingested.\"\"\"\n",
        "    return list_resumes()\n",
        "\n",
        "@tool\n",
        "def search_resumes_tool(skills: str):\n",
        "    \"\"\"Search for candidates whose resumes match the given skills. Input should be a comma-separated string of required skills (e.g., 'Python, Machine Learning, Docker'). Use this tool to find candidates for a job opening.\"\"\"\n",
        "    return search_resumes(skills)\n",
        "\n",
        "@tool\n",
        "def clear_resumes_tool():\n",
        "    \"\"\"Clear all resumes from the vector database. This will delete the entire resume database. Use this tool to start fresh or remove all stored resume data.\"\"\"\n",
        "    return clear_resumes()\n",
        "\n",
        "# Create a list of all available tools\n",
        "tools = [\n",
        "    ingest_resumes_tool,\n",
        "    list_resumes_tool,\n",
        "    search_resumes_tool,\n",
        "    clear_resumes_tool\n",
        "]\n",
        "\n",
        "# Initialize the LLM\n",
        "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
        "\n",
        "# Create the agent\n",
        "agent_executor = create_agent(llm, tools)\n",
        "\n",
        "print(\"‚úì Agent and tools set up successfully.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d0466977",
      "metadata": {
        "id": "d0466977"
      },
      "source": [
        "### 3. Use the Agent with Natural Language Queries\n",
        "\n",
        "Now you can interact with your agent using natural language, and it will decide which tool (or tools) to use."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "e23d1f0d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 435
        },
        "id": "e23d1f0d",
        "outputId": "0c6cdf41-dec2-4d28-e27a-921798d0f329"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Agent Query: List resumes ---\n",
            "üìã Listing resumes...\n",
            " 1. mantu_nigam_resume.txt\n",
            " 2. raj_patel_resume.txt\n",
            " 3. sarah_johnson_resume.txt\n",
            " 4. vinod_malik_resume.txt\n",
            "Agent Response: You have the following resumes in the database:\n",
            "\n",
            "1. mantu_nigam_resume.txt\n",
            "2. raj_patel_resume.txt\n",
            "3. sarah_johnson_resume.txt\n",
            "4. vinod_malik_resume.txt\n",
            "\n",
            "--- Agent Query: Search for candidates with Angular and NestJS ---\n",
            "üîç Searching for candidates with skills: Angular, NestJS\n",
            "\n",
            "============================================================\n",
            "üéØ SEARCH RESULTS\n",
            "============================================================\n",
            "### Top 3 Candidates\n",
            "\n",
            "1. **Sarah Johnson**\n",
            "   - **Relevant Skills:** Angular, NestJS, TypeScript, Node.js\n",
            "   - **Why They Are a Good Fit:** Sarah has direct experience as a Full Stack Developer, specifically building microservices with NestJS and developing UIs with Angular. Her educational background in Computer Science from Stanford adds to her qualifications.\n",
            "   - **Matching Percentage:** 100%\n",
            "\n",
            "2. **Mantu Nigam**\n",
            "   - **Relevant Skills:** Angular, Nest, React, HTML, CSS\n",
            "   - **Why They Are a Good Fit:** Mantu has built full stack applications using both Angular and Nest, demonstrating practical experience with the required technologies. His role as a Senior AI Engineer indicates a strong technical background, although he has less direct experience with NestJS compared to Sarah.\n",
            "   - **Matching Percentage:** 90%\n",
            "\n",
            "3. **Raj Patel**\n",
            "   - **Relevant Skills:** (No relevant skills for Angular or NestJS)\n",
            "   - **Why They Are a Good Fit:** Raj does not possess the required skills in Angular or NestJS, focusing instead on Python and backend technologies. Therefore, he is not a suitable candidate for this position.\n",
            "   - **Matching Percentage:** 0%\n",
            "\n",
            "### Summary\n",
            "- **Sarah Johnson** is the top candidate with full proficiency in both required skills.\n",
            "- **Mantu Nigam** follows closely with relevant experience but slightly less focus on NestJS.\n",
            "- **Raj Patel** does not meet the skill requirements for this role.\n",
            "============================================================\n",
            "Agent Response: Here are the top candidates who are proficient in Angular and NestJS:\n",
            "\n",
            "1. **Sarah Johnson**\n",
            "   - **Relevant Skills:** Angular, NestJS, TypeScript, Node.js\n",
            "   - **Why They Are a Good Fit:** Sarah has direct experience as a Full Stack Developer, specifically building microservices with NestJS and developing UIs with Angular. Her educational background in Computer Science from Stanford adds to her qualifications.\n",
            "   - **Matching Percentage:** 100%\n",
            "\n",
            "2. **Mantu Nigam**\n",
            "   - **Relevant Skills:** Angular, Nest, React, HTML, CSS\n",
            "   - **Why They Are a Good Fit:** Mantu has built full stack applications using both Angular and Nest, demonstrating practical experience with the required technologies. His role as a Senior AI Engineer indicates a strong technical background, although he has less direct experience with NestJS compared to Sarah.\n",
            "   - **Matching Percentage:** 90%\n",
            "\n",
            "3. **Raj Patel**\n",
            "   - **Relevant Skills:** (No relevant skills for Angular or NestJS)\n",
            "   - **Why They Are a Good Fit:** Raj does not possess the required skills in Angular or NestJS, focusing instead on Python and backend technologies. Therefore, he is not a suitable candidate for this position.\n",
            "   - **Matching Percentage:** 0%\n",
            "\n",
            "### Summary\n",
            "- **Sarah Johnson** is the top candidate with full proficiency in both required skills.\n",
            "- **Mantu Nigam** follows closely with relevant experience but slightly less focus on NestJS.\n",
            "- **Raj Patel** does not meet the skill requirements for this role.\n"
          ]
        }
      ],
      "source": [
        "from langchain_core.messages import HumanMessage\n",
        "\n",
        "# Example 1: List existing resumes\n",
        "print(\"\\n--- Agent Query: List resumes ---\")\n",
        "response = agent_executor.invoke({\n",
        "    \"messages\": [HumanMessage(content=\"What resumes do I have?\")]\n",
        "})\n",
        "print(\"Agent Response:\", response[\"messages\"][-1].content)\n",
        "\n",
        "# Example 2: Search for candidates\n",
        "print(\"\\n--- Agent Query: Search for candidates with Angular and NestJS ---\")\n",
        "response = agent_executor.invoke({\n",
        "    \"messages\": [HumanMessage(content=\"Find candidates who are good in Angular and NestJS.\")]\n",
        "})\n",
        "print(\"Agent Response:\", response[\"messages\"][-1].content)\n",
        "\n",
        "# Example 3: Ingest resumes (if you had new files in ./resumes folder)\n",
        "# Make sure there are new files in the './resumes' directory before running this example\n",
        "# print(\"\\n--- Agent Query: Ingest new resumes ---\")\n",
        "# response = agent_executor.invoke({\n",
        "#     \"messages\": [HumanMessage(content=\"Please process any new resumes.\")]\n",
        "# })\n",
        "# print(\"Agent Response:\", response[\"messages\"][-1].content)\n",
        "\n",
        "# Example 4: Clear the database\n",
        "# print(\"\\n--- Agent Query: Clear all resume data ---\")\n",
        "# response = agent_executor.invoke({\n",
        "#     \"messages\": [HumanMessage(content=\"Delete all stored resumes.\")]\n",
        "# })\n",
        "# print(\"Agent Response:\", response[\"messages\"][-1].content)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "0ef98f7e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ef98f7e",
        "outputId": "fdc23856-c964-45ab-a17f-df8a567010f4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úì Cleaned up old database\n",
            "‚úì Ready for fresh start\n"
          ]
        }
      ],
      "source": [
        "import shutil\n",
        "import os\n",
        "\n",
        "# Remove corrupted database\n",
        "if os.path.exists(\"./resume_db\"):\n",
        "    shutil.rmtree(\"./resume_db\")\n",
        "    print(\"‚úì Cleaned up old database\")\n",
        "\n",
        "# Recreate folder\n",
        "os.makedirs(\"./resume_db\", exist_ok=True)\n",
        "print(\"‚úì Ready for fresh start\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "NpW7GOVicTF0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NpW7GOVicTF0",
        "outputId": "a4e3d6c7-ceef-45ae-81b5-cdee5b74aec0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "VINOD MALIK\n",
            "vinod.malik@email.com | +91-9876543210 | Bangalore\n",
            "\n",
            "SKILLS\n",
            "Python, LangChain, VectorDB, Google Cloud, Docker\n",
            "\n",
            "EXPERIENCE\n",
            "Senior AI Engineer | TechCorp | 2021-Present\n",
            "- Built Full stack Gen AI App\n",
            "- Developed Mobile App Using Material UI\n",
            "\n",
            "Software Engineer | TCS | 2022-2025\n",
            "- Created ML models and REST APIs with Python\n",
            "\n",
            "EDUCATION\n",
            "MCA | IPU Delhi | 2011\n"
          ]
        }
      ],
      "source": [
        "def generate_resume(data):\n",
        "    \"\"\"Generate a text resume from data dictionary\"\"\"\n",
        "    resume = []\n",
        "\n",
        "    # Header\n",
        "    resume.append(data['name'].upper())\n",
        "    resume.append(f\"{data['email']} | {data['phone']} | {data['location']}\")\n",
        "    resume.append(\"\")\n",
        "\n",
        "    # Skills\n",
        "    resume.append(\"SKILLS\")\n",
        "    resume.append(\", \".join(data['skills']))\n",
        "    resume.append(\"\")\n",
        "\n",
        "    # Experience\n",
        "    resume.append(\"EXPERIENCE\")\n",
        "    for exp in data['experiences']:\n",
        "        resume.append(f\"{exp['title']} | {exp['company']} | {exp['duration']}\")\n",
        "        for resp in exp['responsibilities']:\n",
        "            resume.append(f\"- {resp}\")\n",
        "        resume.append(\"\")\n",
        "\n",
        "    # Education\n",
        "    resume.append(\"EDUCATION\")\n",
        "    edu = data['education']\n",
        "    resume.append(f\"{edu['degree']} | {edu['institution']} | {edu['year']}\")\n",
        "\n",
        "    return \"\\n\".join(resume)\n",
        "\n",
        "\n",
        "def save_resume(data, filepath):\n",
        "    \"\"\"Save resume to file\"\"\"\n",
        "    with open(filepath, 'w') as f:\n",
        "        f.write(generate_resume(data))\n",
        "\n",
        "\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    resume_data = {\n",
        "        \"name\": \"Vinod Malik\",\n",
        "        \"email\": \"vinod.malik@email.com\",\n",
        "        \"phone\": \"+91-9876543210\",\n",
        "        \"location\": \"Bangalore\",\n",
        "        \"skills\": [\"Python\", \"LangChain\", \"VectorDB\", \"Google Cloud\", \"Docker\"],\n",
        "        \"experiences\": [\n",
        "            {\n",
        "                \"title\": \"Senior AI Engineer\",\n",
        "                \"company\": \"TechCorp\",\n",
        "                \"duration\": \"2021-Present\",\n",
        "                \"responsibilities\": [\n",
        "                    \"Built Full stack Gen AI App\",\n",
        "                    \"Developed Mobile App Using Material UI\"\n",
        "                ]\n",
        "            },\n",
        "            {\n",
        "                \"title\": \"Software Engineer\",\n",
        "                \"company\": \"TCS\",\n",
        "                \"duration\": \"2022-2025\",\n",
        "                \"responsibilities\": [\n",
        "                    \"Created ML models and REST APIs with Python\"\n",
        "                ]\n",
        "            }\n",
        "        ],\n",
        "        \"education\": {\n",
        "            \"degree\": \"MCA\",\n",
        "            \"institution\": \"IPU Delhi\",\n",
        "            \"year\": \"2011\"\n",
        "        }\n",
        "    }\n",
        "\n",
        "    # Generate and print\n",
        "    print(generate_resume(resume_data))\n",
        "\n",
        "    # Save to file\n",
        "    save_resume(resume_data, \"resumes/vinod_malik_resume.txt\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "113105d0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "113105d0",
        "outputId": "966e7a6d-5c60-4b6a-8257-219b9e0081d6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üì• Ingesting resumes...\n",
            "‚úì Created new database with 2 chunks from 2 resumes\n",
            "‚úì Database saved successfully\n"
          ]
        }
      ],
      "source": [
        "# Add resumes to database\n",
        "ingest_resumes()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0fde6dcd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 499
        },
        "id": "0fde6dcd",
        "outputId": "246ce70e-3d28-4910-a7b7-1933fc74b384"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üîç Searching for candidates with skills: front end, angular, react, microservice using nestjs\n",
            "\n",
            "============================================================\n",
            "üéØ SEARCH RESULTS\n",
            "============================================================\n",
            "### Top Candidates Summary\n",
            "\n",
            "**1. Mantu Nigam**  \n",
            "- **Relevant Skills:** React, Angular, Nest, Full stack development  \n",
            "- **Why They Are a Good Fit:** Mantu has direct experience building full stack applications using Angular and Nest, which aligns perfectly with the required skills. His background in both front-end and back-end technologies makes him a strong candidate for roles involving microservices.  \n",
            "- **Matching Percentage:** 90%\n",
            "\n",
            "**2. Vinod Malik**  \n",
            "- **Relevant Skills:** (Limited relevant skills)  \n",
            "- **Why They Are a Good Fit:** While Vinod has experience as a Senior AI Engineer, his resume does not mention any front-end technologies like Angular or React, nor does it indicate experience with microservices using Nest. His skills are more focused on AI and Python, making him less suitable for the required role.  \n",
            "- **Matching Percentage:** 40%\n",
            "\n",
            "### Summary\n",
            "Mantu Nigam is the clear top candidate due to his relevant experience with both Angular and Nest, while Vinod Malik lacks the necessary front-end skills.\n",
            "============================================================\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'### Top Candidates Summary\\n\\n**1. Mantu Nigam**  \\n- **Relevant Skills:** React, Angular, Nest, Full stack development  \\n- **Why They Are a Good Fit:** Mantu has direct experience building full stack applications using Angular and Nest, which aligns perfectly with the required skills. His background in both front-end and back-end technologies makes him a strong candidate for roles involving microservices.  \\n- **Matching Percentage:** 90%\\n\\n**2. Vinod Malik**  \\n- **Relevant Skills:** (Limited relevant skills)  \\n- **Why They Are a Good Fit:** While Vinod has experience as a Senior AI Engineer, his resume does not mention any front-end technologies like Angular or React, nor does it indicate experience with microservices using Nest. His skills are more focused on AI and Python, making him less suitable for the required role.  \\n- **Matching Percentage:** 40%\\n\\n### Summary\\nMantu Nigam is the clear top candidate due to his relevant experience with both Angular and Nest, while Vinod Malik lacks the necessary front-end skills.'"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Search for candidates with specific skills\n",
        "skills = \"front end, angular, react, microservice using nestjs\"  # Change this to your required skills\n",
        "search_resumes(skills)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "BvzuhqPfeh4Y",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 534
        },
        "id": "BvzuhqPfeh4Y",
        "outputId": "3fdddb1f-625e-4eaa-862d-626ccf94a8c4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üîç Searching for candidates with skills: python, ML, Gen AI\n",
            "\n",
            "============================================================\n",
            "üéØ SEARCH RESULTS\n",
            "============================================================\n",
            "### Top 3 Candidates\n",
            "\n",
            "1. **Vinod Malik**\n",
            "   - **Relevant Skills:** Python, Machine Learning, Gen AI (LangChain)\n",
            "   - **Why They Are a Good Fit:** Vinod has extensive experience in building Gen AI applications using Python and LangChain, along with a solid background in developing ML models. His current role as a Senior AI Engineer aligns well with the required skills.\n",
            "   - **Matching Percentage:** 95%\n",
            "\n",
            "2. **Raj Patel**\n",
            "   - **Relevant Skills:** Python, Docker, Machine Learning (implied through API development)\n",
            "   - **Why They Are a Good Fit:** While Raj's experience is more focused on backend development, he has strong Python skills and experience with Docker. However, he lacks direct experience in Gen AI and ML, which slightly lowers his fit.\n",
            "   - **Matching Percentage:** 75%\n",
            "\n",
            "3. **Mantu Nigam**\n",
            "   - **Relevant Skills:** Python, Machine Learning (implied through API development)\n",
            "   - **Why They Are a Good Fit:** Mantu has Python skills and experience in creating ML models, but lacks direct experience in Gen AI. His focus on full-stack applications may not align as closely with the specific requirements.\n",
            "   - **Matching Percentage:** 70% \n",
            "\n",
            "### Summary\n",
            "- **Vinod Malik** is the strongest candidate due to his direct experience with Gen AI and ML.\n",
            "- **Raj Patel** has solid Python skills and backend experience but lacks Gen AI expertise.\n",
            "- **Mantu Nigam** has relevant skills but is less aligned with the specific requirements for Gen AI.\n",
            "============================================================\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "\"### Top 3 Candidates\\n\\n1. **Vinod Malik**\\n   - **Relevant Skills:** Python, Machine Learning, Gen AI (LangChain)\\n   - **Why They Are a Good Fit:** Vinod has extensive experience in building Gen AI applications using Python and LangChain, along with a solid background in developing ML models. His current role as a Senior AI Engineer aligns well with the required skills.\\n   - **Matching Percentage:** 95%\\n\\n2. **Raj Patel**\\n   - **Relevant Skills:** Python, Docker, Machine Learning (implied through API development)\\n   - **Why They Are a Good Fit:** While Raj's experience is more focused on backend development, he has strong Python skills and experience with Docker. However, he lacks direct experience in Gen AI and ML, which slightly lowers his fit.\\n   - **Matching Percentage:** 75%\\n\\n3. **Mantu Nigam**\\n   - **Relevant Skills:** Python, Machine Learning (implied through API development)\\n   - **Why They Are a Good Fit:** Mantu has Python skills and experience in creating ML models, but lacks direct experience in Gen AI. His focus on full-stack applications may not align as closely with the specific requirements.\\n   - **Matching Percentage:** 70% \\n\\n### Summary\\n- **Vinod Malik** is the strongest candidate due to his direct experience with Gen AI and ML.\\n- **Raj Patel** has solid Python skills and backend experience but lacks Gen AI expertise.\\n- **Mantu Nigam** has relevant skills but is less aligned with the specific requirements for Gen AI.\""
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Search for candidates with specific skills\n",
        "skills = \"python, ML, Gen AI\"  # Change this to your required skills\n",
        "search_resumes(skills)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
