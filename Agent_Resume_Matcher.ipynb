{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "4f7a981c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "4f7a981c",
        "outputId": "2568f6c6-12a9-44ba-f1e5-fe21f85dc76e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: langchain-openai in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (1.1.6)\n",
            "Requirement already satisfied: langchain-community in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (0.4.1)\n",
            "Requirement already satisfied: langchain-text-splitters in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (1.1.0)\n",
            "Requirement already satisfied: langchain-core in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (1.2.5)\n",
            "Requirement already satisfied: faiss-cpu in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (1.13.2)\n",
            "Requirement already satisfied: python-dotenv in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (1.2.1)\n",
            "Requirement already satisfied: pypdf in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (6.5.0)\n",
            "Requirement already satisfied: langsmith in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (0.5.0)\n",
            "Requirement already satisfied: openai<3.0.0,>=1.109.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from langchain-openai) (2.14.0)\n",
            "Requirement already satisfied: tiktoken<1.0.0,>=0.7.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from langchain-openai) (0.12.0)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from langchain-core) (1.33)\n",
            "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from langchain-core) (25.0)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from langchain-core) (2.12.5)\n",
            "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from langchain-core) (6.0.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from langchain-core) (9.1.2)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from langchain-core) (4.15.0)\n",
            "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from langchain-core) (0.12.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from langsmith) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from langsmith) (3.11.5)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from langsmith) (1.0.0)\n",
            "Requirement already satisfied: requests>=2.0.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from langsmith) (2.32.5)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from langsmith) (0.25.0)\n",
            "Requirement already satisfied: anyio in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from httpx<1,>=0.23.0->langsmith) (4.12.0)\n",
            "Requirement already satisfied: certifi in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from httpx<1,>=0.23.0->langsmith) (2025.11.12)\n",
            "Requirement already satisfied: httpcore==1.* in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from httpx<1,>=0.23.0->langsmith) (1.0.9)\n",
            "Requirement already satisfied: idna in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from httpx<1,>=0.23.0->langsmith) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core) (3.0.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.10.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (0.12.0)\n",
            "Requirement already satisfied: sniffio in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (4.67.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.5 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core) (2.41.5)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core) (0.4.2)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from tiktoken<1.0.0,>=0.7.0->langchain-openai) (2025.11.3)\n",
            "Requirement already satisfied: langchain-classic<2.0.0,>=1.0.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from langchain-community) (1.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3.0.0,>=1.4.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from langchain-community) (2.0.45)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from langchain-community) (3.13.2)\n",
            "Requirement already satisfied: dataclasses-json<0.7.0,>=0.6.7 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from langchain-community) (0.6.7)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from langchain-community) (2.12.0)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from langchain-community) (0.4.3)\n",
            "Requirement already satisfied: numpy>=2.1.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from langchain-community) (2.4.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.22.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community) (3.26.2)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community) (0.9.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from requests>=2.0.0->langsmith) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from requests>=2.0.0->langsmith) (2.6.2)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain-community) (1.1.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install langchain-openai langchain-community langchain-text-splitters langchain-core faiss-cpu python-dotenv pypdf langchain-openai langsmith"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "faf9e212",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "faf9e212",
        "outputId": "8dae7b19-013e-4fca-d283-b8a872a1ec6a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ“ Setup complete\n",
            "API Key: sk-proj-2D_k1B8OV3MW...\n",
            "âœ“ Folders created: ./resumes and ./resume_db\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import shutil\n",
        "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from langchain_community.document_loaders import TextLoader, DirectoryLoader, PyPDFLoader\n",
        "from dotenv import load_dotenv\n",
        "# from google.colab import userdata\n",
        "\n",
        "# Load API key\n",
        "# os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')\n",
        "load_dotenv()\n",
        "print(\"âœ“ Setup complete\")\n",
        "print(\"API Key:\", os.environ.get(\"OPENAI_API_KEY\", \"Not set\")[:20] + \"...\")\n",
        "\n",
        "# Create folders if they don't exist\n",
        "os.makedirs(\"./resumes\", exist_ok=True)\n",
        "os.makedirs(\"./resume_db\", exist_ok=True)\n",
        "print(\"âœ“ Folders created: ./resumes and ./resume_db\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a0eb34f5",
      "metadata": {
        "id": "a0eb34f5"
      },
      "source": [
        "### 1. Define your functions as LangChain Tools\n",
        "\n",
        "LangChain's `@tool` decorator allows you to expose Python functions to an LLM agent. The docstring of the function is crucial as the agent uses it to understand what the tool does and what arguments it expects."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "112f54c3",
      "metadata": {
        "id": "112f54c3"
      },
      "outputs": [],
      "source": [
        "from langchain.tools import tool\n",
        "\n",
        "# Wrap the existing functions as tools\n",
        "\n",
        "@tool\n",
        "def ingest_resumes_tool():\n",
        "    \"\"\"Ingest new resumes from the './resumes' folder into the vector database. Use this tool when new resumes need to be processed or the database needs to be updated.\"\"\"\n",
        "    return ingest_resumes()\n",
        "\n",
        "@tool\n",
        "def list_resumes_tool():\n",
        "    \"\"\"List all the unique resume file names currently stored in the vector database. Use this tool to see what resumes have been ingested.\"\"\"\n",
        "    return list_resumes()\n",
        "\n",
        "@tool\n",
        "def search_resumes_tool(skills: str):\n",
        "    \"\"\"Search for candidates whose resumes match the given skills. Input should be a comma-separated string of required skills (e.g., 'Python, Machine Learning, Docker'). Use this tool to find candidates for a job opening.\"\"\"\n",
        "    return search_resumes(skills)\n",
        "\n",
        "@tool\n",
        "def clear_resumes_tool():\n",
        "    \"\"\"Clear all resumes from the vector database. This will delete the entire resume database. Use this tool to start fresh or remove all stored resume data.\"\"\"\n",
        "    return clear_resumes()\n",
        "\n",
        "# Note: generate_resume and save_resume are not included as direct agent tools here\n",
        "# because they typically involve structured input (dictionaries) that are harder for a generic agent to construct directly from natural language.\n",
        "# However, you could create a more complex tool that takes simpler inputs and then constructs the dictionary internally.\n",
        "\n",
        "\n",
        "# Create a list of all available tools\n",
        "tools = [\n",
        "    ingest_resumes_tool,\n",
        "    list_resumes_tool,\n",
        "    search_resumes_tool,\n",
        "    clear_resumes_tool\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "080becf9",
      "metadata": {
        "id": "080becf9"
      },
      "source": [
        "### 2. Set up the LangChain Agent\n",
        "\n",
        "Now, you'll need an LLM to act as the agent's 'brain' and an `AgentExecutor` to run the agent with the defined tools."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "f79043b7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 378
        },
        "id": "f79043b7",
        "outputId": "3c2dbb70-3c0d-4914-d5a6-665c5e067392"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ“ Agent and tools set up successfully.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import shutil\n",
        "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
        "from langchain_core.tools import tool\n",
        "from langchain_core.messages import HumanMessage\n",
        "from langchain.agents import create_agent\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from langchain_community.document_loaders import TextLoader, DirectoryLoader, PyPDFLoader\n",
        "\n",
        "# Initialize embeddings globally\n",
        "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
        "\n",
        "# Define the actual resume management functions\n",
        "\n",
        "def ingest_resumes():\n",
        "    \"\"\"Load resumes from ./resumes folder and add to vector database\"\"\"\n",
        "    print(\"ðŸ“¥ Ingesting resumes...\")\n",
        "    # Load text files\n",
        "    txt_loader = DirectoryLoader(\"./resumes\", glob=\"**/*.txt\", loader_cls=TextLoader)\n",
        "    txt_docs = txt_loader.load()\n",
        "    # Load PDF files\n",
        "    pdf_loader = DirectoryLoader(\"./resumes\", glob=\"**/*.pdf\", loader_cls=PyPDFLoader)\n",
        "    pdf_docs = pdf_loader.load()\n",
        "    all_docs = txt_docs + pdf_docs\n",
        "    \n",
        "    if not all_docs:\n",
        "        print(\"âŒ No resumes found in ./resumes folder\")\n",
        "        return \"No resumes found in ./resumes folder\"\n",
        "    \n",
        "    # Split documents into chunks\n",
        "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
        "    chunks = text_splitter.split_documents(all_docs)\n",
        "    \n",
        "    # Check if FAISS index file exists (not just folder)\n",
        "    db_file_exists = os.path.exists(\"./resume_db/index.faiss\")\n",
        "    \n",
        "    if db_file_exists:\n",
        "        # Load existing and add new documents\n",
        "        vectorstore = FAISS.load_local(\"./resume_db\", embeddings, allow_dangerous_deserialization=True)\n",
        "        vectorstore.add_documents(chunks)\n",
        "        print(f\"âœ“ Added {len(chunks)} chunks from {len(all_docs)} resumes\")\n",
        "        result = f\"Added {len(chunks)} chunks from {len(all_docs)} resumes to existing database\"\n",
        "    else:\n",
        "        # Create new vector store\n",
        "        vectorstore = FAISS.from_documents(chunks, embeddings)\n",
        "        print(f\"âœ“ Created new database with {len(chunks)} chunks from {len(all_docs)} resumes\")\n",
        "        result = f\"Created new database with {len(chunks)} chunks from {len(all_docs)} resumes\"\n",
        "    \n",
        "    vectorstore.save_local(\"./resume_db\")\n",
        "    print(\"âœ“ Database saved successfully\")\n",
        "    return result\n",
        "\n",
        "def list_resumes():\n",
        "    \"\"\"List all resumes stored in vector database\"\"\"\n",
        "    print(\"ðŸ“‹ Listing resumes...\")\n",
        "    if not os.path.exists(\"./resume_db/index.faiss\"):\n",
        "        print(\"âŒ No database found. Please ingest resumes first.\")\n",
        "        return \"No database found. Please ingest resumes first.\"\n",
        "    \n",
        "    vectorstore = FAISS.load_local(\"./resume_db\", embeddings, allow_dangerous_deserialization=True)\n",
        "    # Get all documents\n",
        "    all_docs = vectorstore.docstore._dict\n",
        "    \n",
        "    # Extract unique sources\n",
        "    sources = set()\n",
        "    for doc in all_docs.values():\n",
        "        if hasattr(doc, 'metadata') and 'source' in doc.metadata:\n",
        "            sources.add(os.path.basename(doc.metadata['source']))\n",
        "    \n",
        "    result = f\"Found {len(sources)} resumes in database:\\n\"\n",
        "    for i, source in enumerate(sorted(sources), 1):\n",
        "        result += f\"{i}. {source}\\n\"\n",
        "        print(f\" {i}. {source}\")\n",
        "    \n",
        "    return result\n",
        "\n",
        "def search_resumes(skills):\n",
        "    \"\"\"Search resumes by skills and return best matches\"\"\"\n",
        "    print(f\"ðŸ” Searching for candidates with skills: {skills}\")\n",
        "    if not os.path.exists(\"./resume_db/index.faiss\"):\n",
        "        print(\"âŒ No database found. Please ingest resumes first.\")\n",
        "        return \"No database found. Please ingest resumes first.\"\n",
        "    \n",
        "    vectorstore = FAISS.load_local(\"./resume_db\", embeddings, allow_dangerous_deserialization=True)\n",
        "    \n",
        "    # Search for relevant resume chunks\n",
        "    retriever = vectorstore.as_retriever(search_kwargs={\"k\": 5})\n",
        "    docs = retriever.invoke(skills)\n",
        "    \n",
        "    # Create context from retrieved documents\n",
        "    context = \"\\n\\n\".join([f\"Resume {i+1}:\\n{doc.page_content}\" for i, doc in enumerate(docs)])\n",
        "    \n",
        "    # Create prompt for LLM\n",
        "    prompt = f\"\"\"You are a recruiter assistant. Based on the following resume excerpts, identify and rank the best candidates for the required skills.\n",
        "\n",
        "Required Skills: {skills}\n",
        "\n",
        "Resume Excerpts:\n",
        "{context}\n",
        "\n",
        "Please provide a quick summary for the top 3 best matching candidates. For each candidate, include their relevant skills, why they are a good fit, and a matching percentage. The response should be concise.\n",
        "\n",
        "Answer:\"\"\"\n",
        "    \n",
        "    # Get LLM response\n",
        "    llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
        "    response = llm.invoke(prompt)\n",
        "    \n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"ðŸŽ¯ SEARCH RESULTS\")\n",
        "    print(\"=\"*60)\n",
        "    print(response.content)\n",
        "    print(\"=\"*60)\n",
        "    \n",
        "    return response.content\n",
        "\n",
        "def clear_resumes():\n",
        "    \"\"\"Clear all resumes from vector database\"\"\"\n",
        "    print(\"ðŸ—‘ï¸ Clearing resume database...\")\n",
        "    if os.path.exists(\"./resume_db\"):\n",
        "        shutil.rmtree(\"./resume_db\")\n",
        "        print(\"âœ“ Database cleared successfully\")\n",
        "        return \"Database cleared successfully\"\n",
        "    else:\n",
        "        print(\"âŒ No database found\")\n",
        "        return \"No database found\"\n",
        "\n",
        "# Now wrap the functions as tools\n",
        "\n",
        "@tool\n",
        "def ingest_resumes_tool():\n",
        "    \"\"\"Ingest new resumes from the './resumes' folder into the vector database. Use this tool when new resumes need to be processed or the database needs to be updated.\"\"\"\n",
        "    return ingest_resumes()\n",
        "\n",
        "@tool\n",
        "def list_resumes_tool():\n",
        "    \"\"\"List all the unique resume file names currently stored in the vector database. Use this tool to see what resumes have been ingested.\"\"\"\n",
        "    return list_resumes()\n",
        "\n",
        "@tool\n",
        "def search_resumes_tool(skills: str):\n",
        "    \"\"\"Search for candidates whose resumes match the given skills. Input should be a comma-separated string of required skills (e.g., 'Python, Machine Learning, Docker'). Use this tool to find candidates for a job opening.\"\"\"\n",
        "    return search_resumes(skills)\n",
        "\n",
        "@tool\n",
        "def clear_resumes_tool():\n",
        "    \"\"\"Clear all resumes from the vector database. This will delete the entire resume database. Use this tool to start fresh or remove all stored resume data.\"\"\"\n",
        "    return clear_resumes()\n",
        "\n",
        "# Create a list of all available tools\n",
        "tools = [\n",
        "    ingest_resumes_tool,\n",
        "    list_resumes_tool,\n",
        "    search_resumes_tool,\n",
        "    clear_resumes_tool\n",
        "]\n",
        "\n",
        "# Initialize the LLM\n",
        "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
        "\n",
        "# Create the agent\n",
        "agent_executor = create_agent(llm, tools)\n",
        "\n",
        "print(\"âœ“ Agent and tools set up successfully.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d0466977",
      "metadata": {
        "id": "d0466977"
      },
      "source": [
        "### 3. Use the Agent with Natural Language Queries\n",
        "\n",
        "Now you can interact with your agent using natural language, and it will decide which tool (or tools) to use."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "e23d1f0d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 435
        },
        "id": "e23d1f0d",
        "outputId": "0c6cdf41-dec2-4d28-e27a-921798d0f329"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Agent Query: List resumes ---\n",
            "ðŸ“‹ Listing resumes...\n",
            " 1. mantu_nigam_resume.txt\n",
            " 2. vinod_malik_resume.txt\n",
            "Agent Response: You have the following resumes in the database:\n",
            "\n",
            "1. mantu_nigam_resume.txt\n",
            "2. vinod_malik_resume.txt\n",
            "\n",
            "--- Agent Query: Search for candidates with Angular and NestJS ---\n",
            "ðŸ” Searching for candidates with skills: Angular, NestJS\n",
            "\n",
            "============================================================\n",
            "ðŸŽ¯ SEARCH RESULTS\n",
            "============================================================\n",
            "### Top Candidates for Required Skills: Angular, NestJS\n",
            "\n",
            "#### 1. Mantu Nigam\n",
            "- **Relevant Skills:** Angular, Nest, Python, React, HTML, CSS, Google Cloud, Docker\n",
            "- **Why They Are a Good Fit:** Mantu has direct experience building full-stack applications using both Angular and Nest, which aligns perfectly with the required skills. His background in AI engineering also adds value to his technical expertise.\n",
            "- **Matching Percentage:** 100%\n",
            "\n",
            "#### 2. Vinod Malik\n",
            "- **Relevant Skills:** Python, LangChain, VectorDB, Google Cloud, Docker\n",
            "- **Why They Are a Good Fit:** While Vinod has a strong background in AI and cloud technologies, he lacks experience with Angular and NestJS specifically. His skills in Python and other technologies are valuable, but he does not meet the primary requirements.\n",
            "- **Matching Percentage:** 0%\n",
            "\n",
            "### Summary\n",
            "- **Mantu Nigam** is the only candidate who meets the required skills of Angular and NestJS, making him the top choice. Vinod Malik, while skilled, does not possess the necessary experience in the specified technologies.\n",
            "============================================================\n",
            "Agent Response: The top candidate for the required skills of Angular and NestJS is:\n",
            "\n",
            "#### Mantu Nigam\n",
            "- **Relevant Skills:** Angular, Nest, Python, React, HTML, CSS, Google Cloud, Docker\n",
            "- **Why They Are a Good Fit:** Mantu has direct experience building full-stack applications using both Angular and Nest, which aligns perfectly with the required skills. His background in AI engineering also adds value to his technical expertise.\n",
            "- **Matching Percentage:** 100%\n",
            "\n",
            "Unfortunately, another candidate, Vinod Malik, does not meet the primary requirements as he lacks experience with Angular and NestJS. \n",
            "\n",
            "Mantu Nigam is the best fit for your needs!\n"
          ]
        }
      ],
      "source": [
        "from langchain_core.messages import HumanMessage\n",
        "\n",
        "# Example 1: List existing resumes\n",
        "print(\"\\n--- Agent Query: List resumes ---\")\n",
        "response = agent_executor.invoke({\n",
        "    \"messages\": [HumanMessage(content=\"What resumes do I have?\")]\n",
        "})\n",
        "print(\"Agent Response:\", response[\"messages\"][-1].content)\n",
        "\n",
        "# Example 2: Search for candidates\n",
        "print(\"\\n--- Agent Query: Search for candidates with Angular and NestJS ---\")\n",
        "response = agent_executor.invoke({\n",
        "    \"messages\": [HumanMessage(content=\"Find candidates who are good in Angular and NestJS.\")]\n",
        "})\n",
        "print(\"Agent Response:\", response[\"messages\"][-1].content)\n",
        "\n",
        "# Example 3: Ingest resumes (if you had new files in ./resumes folder)\n",
        "# Make sure there are new files in the './resumes' directory before running this example\n",
        "# print(\"\\n--- Agent Query: Ingest new resumes ---\")\n",
        "# response = agent_executor.invoke({\n",
        "#     \"messages\": [HumanMessage(content=\"Please process any new resumes.\")]\n",
        "# })\n",
        "# print(\"Agent Response:\", response[\"messages\"][-1].content)\n",
        "\n",
        "# Example 4: Clear the database\n",
        "# print(\"\\n--- Agent Query: Clear all resume data ---\")\n",
        "# response = agent_executor.invoke({\n",
        "#     \"messages\": [HumanMessage(content=\"Delete all stored resumes.\")]\n",
        "# })\n",
        "# print(\"Agent Response:\", response[\"messages\"][-1].content)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "0ef98f7e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ef98f7e",
        "outputId": "fdc23856-c964-45ab-a17f-df8a567010f4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ“ Cleaned up old database\n",
            "âœ“ Ready for fresh start\n"
          ]
        }
      ],
      "source": [
        "import shutil\n",
        "import os\n",
        "\n",
        "# Remove corrupted database\n",
        "if os.path.exists(\"./resume_db\"):\n",
        "    shutil.rmtree(\"./resume_db\")\n",
        "    print(\"âœ“ Cleaned up old database\")\n",
        "\n",
        "# Recreate folder\n",
        "os.makedirs(\"./resume_db\", exist_ok=True)\n",
        "print(\"âœ“ Ready for fresh start\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "NpW7GOVicTF0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NpW7GOVicTF0",
        "outputId": "a4e3d6c7-ceef-45ae-81b5-cdee5b74aec0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "VINOD MALIK\n",
            "vinod.malik@email.com | +91-9876543210 | Bangalore\n",
            "\n",
            "SKILLS\n",
            "Python, LangChain, VectorDB, Google Cloud, Docker\n",
            "\n",
            "EXPERIENCE\n",
            "Senior AI Engineer | TechCorp | 2021-Present\n",
            "- Built Full stack Gen AI App\n",
            "- Developed Mobile App Using Material UI\n",
            "\n",
            "Software Engineer | TCS | 2022-2025\n",
            "- Created ML models and REST APIs with Python\n",
            "\n",
            "EDUCATION\n",
            "MCA | IPU Delhi | 2011\n"
          ]
        }
      ],
      "source": [
        "def generate_resume(data):\n",
        "    \"\"\"Generate a text resume from data dictionary\"\"\"\n",
        "    resume = []\n",
        "\n",
        "    # Header\n",
        "    resume.append(data['name'].upper())\n",
        "    resume.append(f\"{data['email']} | {data['phone']} | {data['location']}\")\n",
        "    resume.append(\"\")\n",
        "\n",
        "    # Skills\n",
        "    resume.append(\"SKILLS\")\n",
        "    resume.append(\", \".join(data['skills']))\n",
        "    resume.append(\"\")\n",
        "\n",
        "    # Experience\n",
        "    resume.append(\"EXPERIENCE\")\n",
        "    for exp in data['experiences']:\n",
        "        resume.append(f\"{exp['title']} | {exp['company']} | {exp['duration']}\")\n",
        "        for resp in exp['responsibilities']:\n",
        "            resume.append(f\"- {resp}\")\n",
        "        resume.append(\"\")\n",
        "\n",
        "    # Education\n",
        "    resume.append(\"EDUCATION\")\n",
        "    edu = data['education']\n",
        "    resume.append(f\"{edu['degree']} | {edu['institution']} | {edu['year']}\")\n",
        "\n",
        "    return \"\\n\".join(resume)\n",
        "\n",
        "\n",
        "def save_resume(data, filepath):\n",
        "    \"\"\"Save resume to file\"\"\"\n",
        "    with open(filepath, 'w') as f:\n",
        "        f.write(generate_resume(data))\n",
        "\n",
        "\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    resume_data = {\n",
        "        \"name\": \"Vinod Malik\",\n",
        "        \"email\": \"vinod.malik@email.com\",\n",
        "        \"phone\": \"+91-9876543210\",\n",
        "        \"location\": \"Bangalore\",\n",
        "        \"skills\": [\"Python\", \"LangChain\", \"VectorDB\", \"Google Cloud\", \"Docker\"],\n",
        "        \"experiences\": [\n",
        "            {\n",
        "                \"title\": \"Senior AI Engineer\",\n",
        "                \"company\": \"TechCorp\",\n",
        "                \"duration\": \"2021-Present\",\n",
        "                \"responsibilities\": [\n",
        "                    \"Built Full stack Gen AI App\",\n",
        "                    \"Developed Mobile App Using Material UI\"\n",
        "                ]\n",
        "            },\n",
        "            {\n",
        "                \"title\": \"Software Engineer\",\n",
        "                \"company\": \"TCS\",\n",
        "                \"duration\": \"2022-2025\",\n",
        "                \"responsibilities\": [\n",
        "                    \"Created ML models and REST APIs with Python\"\n",
        "                ]\n",
        "            }\n",
        "        ],\n",
        "        \"education\": {\n",
        "            \"degree\": \"MCA\",\n",
        "            \"institution\": \"IPU Delhi\",\n",
        "            \"year\": \"2011\"\n",
        "        }\n",
        "    }\n",
        "\n",
        "    # Generate and print\n",
        "    print(generate_resume(resume_data))\n",
        "\n",
        "    # Save to file\n",
        "    save_resume(resume_data, \"resumes/vinod_malik_resume.txt\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "113105d0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "113105d0",
        "outputId": "966e7a6d-5c60-4b6a-8257-219b9e0081d6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸ“¥ Ingesting resumes...\n",
            "âœ“ Created new database with 2 chunks from 2 resumes\n",
            "âœ“ Database saved successfully\n"
          ]
        }
      ],
      "source": [
        "# Add resumes to database\n",
        "ingest_resumes()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0fde6dcd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 499
        },
        "id": "0fde6dcd",
        "outputId": "246ce70e-3d28-4910-a7b7-1933fc74b384"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸ” Searching for candidates with skills: front end, angular, react, microservice using nestjs\n",
            "\n",
            "============================================================\n",
            "ðŸŽ¯ SEARCH RESULTS\n",
            "============================================================\n",
            "### Top Candidates Summary\n",
            "\n",
            "**1. Mantu Nigam**  \n",
            "- **Relevant Skills:** React, Angular, Nest, Full stack development  \n",
            "- **Why They Are a Good Fit:** Mantu has direct experience building full stack applications using Angular and Nest, which aligns perfectly with the required skills. His background in both front-end and back-end technologies makes him a strong candidate for roles involving microservices.  \n",
            "- **Matching Percentage:** 90%\n",
            "\n",
            "**2. Vinod Malik**  \n",
            "- **Relevant Skills:** (Limited relevant skills)  \n",
            "- **Why They Are a Good Fit:** While Vinod has experience as a Senior AI Engineer, his resume does not mention any front-end technologies like Angular or React, nor does it indicate experience with microservices using Nest. His skills are more focused on AI and Python, making him less suitable for the required role.  \n",
            "- **Matching Percentage:** 40%\n",
            "\n",
            "### Summary\n",
            "Mantu Nigam is the clear top candidate due to his relevant experience with both Angular and Nest, while Vinod Malik lacks the necessary front-end skills.\n",
            "============================================================\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'### Top Candidates Summary\\n\\n**1. Mantu Nigam**  \\n- **Relevant Skills:** React, Angular, Nest, Full stack development  \\n- **Why They Are a Good Fit:** Mantu has direct experience building full stack applications using Angular and Nest, which aligns perfectly with the required skills. His background in both front-end and back-end technologies makes him a strong candidate for roles involving microservices.  \\n- **Matching Percentage:** 90%\\n\\n**2. Vinod Malik**  \\n- **Relevant Skills:** (Limited relevant skills)  \\n- **Why They Are a Good Fit:** While Vinod has experience as a Senior AI Engineer, his resume does not mention any front-end technologies like Angular or React, nor does it indicate experience with microservices using Nest. His skills are more focused on AI and Python, making him less suitable for the required role.  \\n- **Matching Percentage:** 40%\\n\\n### Summary\\nMantu Nigam is the clear top candidate due to his relevant experience with both Angular and Nest, while Vinod Malik lacks the necessary front-end skills.'"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Search for candidates with specific skills\n",
        "skills = \"front end, angular, react, microservice using nestjs\"  # Change this to your required skills\n",
        "search_resumes(skills)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "BvzuhqPfeh4Y",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 534
        },
        "id": "BvzuhqPfeh4Y",
        "outputId": "3fdddb1f-625e-4eaa-862d-626ccf94a8c4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸ” Searching for candidates with skills: python, ML, Gen AI\n",
            "\n",
            "============================================================\n",
            "ðŸŽ¯ SEARCH RESULTS\n",
            "============================================================\n",
            "### Top Candidates Summary\n",
            "\n",
            "**1. Vinod Malik**  \n",
            "- **Relevant Skills:** Python, ML, Gen AI  \n",
            "- **Why a Good Fit:** Vinod has direct experience in building a full-stack Gen AI application and has created ML models using Python. His role as a Senior AI Engineer indicates a strong background in AI technologies.  \n",
            "- **Matching Percentage:** 95%\n",
            "\n",
            "**2. Mantu Nigam**  \n",
            "- **Relevant Skills:** Python, ML  \n",
            "- **Why a Good Fit:** Mantu has experience in creating ML models and REST APIs with Python. However, he lacks specific experience in Gen AI, which slightly lowers his fit compared to Vinod.  \n",
            "- **Matching Percentage:** 85%\n",
            "\n",
            "**3. (No third candidate)**  \n",
            "- **Why No Third Candidate:** Only two candidates provided relevant experience and skills related to the required skills of Python, ML, and Gen AI. \n",
            "\n",
            "### Summary\n",
            "Vinod Malik is the strongest candidate due to his direct experience with Gen AI, followed by Mantu Nigam, who has solid Python and ML experience but lacks Gen AI exposure.\n",
            "============================================================\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'### Top Candidates Summary\\n\\n**1. Vinod Malik**  \\n- **Relevant Skills:** Python, ML, Gen AI  \\n- **Why a Good Fit:** Vinod has direct experience in building a full-stack Gen AI application and has created ML models using Python. His role as a Senior AI Engineer indicates a strong background in AI technologies.  \\n- **Matching Percentage:** 95%\\n\\n**2. Mantu Nigam**  \\n- **Relevant Skills:** Python, ML  \\n- **Why a Good Fit:** Mantu has experience in creating ML models and REST APIs with Python. However, he lacks specific experience in Gen AI, which slightly lowers his fit compared to Vinod.  \\n- **Matching Percentage:** 85%\\n\\n**3. (No third candidate)**  \\n- **Why No Third Candidate:** Only two candidates provided relevant experience and skills related to the required skills of Python, ML, and Gen AI. \\n\\n### Summary\\nVinod Malik is the strongest candidate due to his direct experience with Gen AI, followed by Mantu Nigam, who has solid Python and ML experience but lacks Gen AI exposure.'"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Search for candidates with specific skills\n",
        "skills = \"python, ML, Gen AI\"  # Change this to your required skills\n",
        "search_resumes(skills)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7D_Pz4qT-Mc8",
      "metadata": {
        "id": "7D_Pz4qT-Mc8"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bb564546",
      "metadata": {
        "id": "bb564546"
      },
      "source": [
        "# Task\n",
        "Set up a LangChain agent with specific tools and test it with example queries."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9001f9be",
      "metadata": {
        "id": "9001f9be"
      },
      "source": [
        "## modify_cell_f79043b7\n",
        "\n",
        "### Subtask:\n",
        "Modify cell `f79043b7` to install `langchain==0.1.17`.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "26a59b7d",
      "metadata": {
        "id": "26a59b7d"
      },
      "source": [
        "**Reasoning**:\n",
        "The subtask is to modify cell `f79043b7` to install `langchain==0.1.17`. I will replace the existing `!pip install langchain` with the specified version and keep the rest of the code in the cell intact.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "818fde02",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "818fde02",
        "outputId": "b474e3dd-1171-4f5d-c951-3a0dd0fbc519"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found existing installation: langchain 1.2.0\n",
            "Uninstalling langchain-1.2.0:\n",
            "  Successfully uninstalled langchain-1.2.0\n",
            "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[0m^C\n"
          ]
        }
      ],
      "source": [
        "langchain_version = \"0.1.17\"\n",
        "!pip uninstall -y langchain\n",
        "!pip install langchain=={langchain_version}\n",
        "\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.agents import create_react_agent # Reverted to common import path\n",
        "from langchain.agents.agent import AgentExecutor # Kept this specific import path\n",
        "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "\n",
        "# Initialize the LLM (make sure OPENAI_API_KEY is set in environment variables)\n",
        "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
        "\n",
        "# Define the agent prompt\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", \"You are a helpful assistant that can manage and search resumes using the provided tools.\"),\n",
        "        MessagesPlaceholder(\"chat_history\"),\n",
        "        (\"human\", \"{input}\"),\n",
        "        MessagesPlaceholder(\"agent_scratchpad\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Create the ReAct agent\n",
        "agent = create_react_agent(llm, tools, prompt)\n",
        "\n",
        "# Create the AgentExecutor\n",
        "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True, handle_parsing_errors=True)\n",
        "\n",
        "print(\"âœ“ Agent and tools set up successfully.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "606ba0be",
      "metadata": {
        "id": "606ba0be"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous attempt to install `langchain==0.1.17` was cancelled. I will re-execute the same code block to ensure the correct version of langchain is installed and the agent setup proceeds as intended.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "09504f1f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "09504f1f",
        "outputId": "ef09b07b-0bdb-4e97-c73c-18f2fb39abdf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[33mWARNING: Skipping langchain as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting langchain==0.1.17\n",
            "  Downloading langchain-0.1.17-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.12/dist-packages (from langchain==0.1.17) (6.0.3)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.12/dist-packages (from langchain==0.1.17) (2.0.45)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.12/dist-packages (from langchain==0.1.17) (3.13.2)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.12/dist-packages (from langchain==0.1.17) (0.6.7)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.12/dist-packages (from langchain==0.1.17) (1.33)\n",
            "Collecting langchain-community<0.1,>=0.0.36 (from langchain==0.1.17)\n",
            "  Downloading langchain_community-0.0.38-py3-none-any.whl.metadata (8.7 kB)\n",
            "Collecting langchain-core<0.2.0,>=0.1.48 (from langchain==0.1.17)\n",
            "  Downloading langchain_core-0.1.53-py3-none-any.whl.metadata (5.9 kB)\n",
            "Collecting langchain-text-splitters<0.1,>=0.0.1 (from langchain==0.1.17)\n",
            "  Downloading langchain_text_splitters-0.0.2-py3-none-any.whl.metadata (2.2 kB)\n",
            "Collecting langsmith<0.2.0,>=0.1.17 (from langchain==0.1.17)\n",
            "  Downloading langsmith-0.1.147-py3-none-any.whl.metadata (14 kB)\n",
            "Collecting numpy<2,>=1 (from langchain==0.1.17)\n",
            "  Downloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.12/dist-packages (from langchain==0.1.17) (2.12.3)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.12/dist-packages (from langchain==0.1.17) (2.32.5)\n",
            "Collecting tenacity<9.0.0,>=8.1.0 (from langchain==0.1.17)\n",
            "  Downloading tenacity-8.5.0-py3-none-any.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.17) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.17) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.17) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.17) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.17) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.17) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.17) (1.22.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain==0.1.17) (3.26.2)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain==0.1.17) (0.9.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0,>=1.33->langchain==0.1.17) (3.0.0)\n",
            "Collecting packaging<24.0,>=23.2 (from langchain-core<0.2.0,>=0.1.48->langchain==0.1.17)\n",
            "  Downloading packaging-23.2-py3-none-any.whl.metadata (3.2 kB)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain==0.1.17) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain==0.1.17) (3.11.5)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain==0.1.17) (1.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1->langchain==0.1.17) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1->langchain==0.1.17) (2.41.4)\n",
            "Requirement already satisfied: typing-extensions>=4.14.1 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1->langchain==0.1.17) (4.15.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1->langchain==0.1.17) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain==0.1.17) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain==0.1.17) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain==0.1.17) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain==0.1.17) (2025.11.12)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3,>=1.4->langchain==0.1.17) (3.3.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain==0.1.17) (4.12.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain==0.1.17) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain==0.1.17) (0.16.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain==0.1.17) (1.1.0)\n",
            "Downloading langchain-0.1.17-py3-none-any.whl (867 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m867.6/867.6 kB\u001b[0m \u001b[31m29.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_community-0.0.38-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m35.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_core-0.1.53-py3-none-any.whl (303 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m303.1/303.1 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_text_splitters-0.0.2-py3-none-any.whl (23 kB)\n",
            "Downloading langsmith-0.1.147-py3-none-any.whl (311 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m311.8/311.8 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.0 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m18.0/18.0 MB\u001b[0m \u001b[31m43.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tenacity-8.5.0-py3-none-any.whl (28 kB)\n",
            "Downloading packaging-23.2-py3-none-any.whl (53 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tenacity, packaging, numpy, langsmith, langchain-core, langchain-text-splitters, langchain-community, langchain\n",
            "  Attempting uninstall: tenacity\n",
            "    Found existing installation: tenacity 9.1.2\n",
            "    Uninstalling tenacity-9.1.2:\n",
            "      Successfully uninstalled tenacity-9.1.2\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 25.0\n",
            "    Uninstalling packaging-25.0:\n",
            "      Successfully uninstalled packaging-25.0\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: langsmith\n",
            "    Found existing installation: langsmith 0.4.59\n",
            "    Uninstalling langsmith-0.4.59:\n",
            "      Successfully uninstalled langsmith-0.4.59\n",
            "  Attempting uninstall: langchain-core\n",
            "    Found existing installation: langchain-core 1.2.5\n",
            "    Uninstalling langchain-core-1.2.5:\n",
            "      Successfully uninstalled langchain-core-1.2.5\n",
            "  Attempting uninstall: langchain-text-splitters\n",
            "    Found existing installation: langchain-text-splitters 1.1.0\n",
            "    Uninstalling langchain-text-splitters-1.1.0:\n",
            "      Successfully uninstalled langchain-text-splitters-1.1.0\n",
            "  Attempting uninstall: langchain-community\n",
            "    Found existing installation: langchain-community 0.4.1\n",
            "    Uninstalling langchain-community-0.4.1:\n",
            "      Successfully uninstalled langchain-community-0.4.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "langchain-classic 1.0.1 requires langchain-core<2.0.0,>=1.2.5, but you have langchain-core 0.1.53 which is incompatible.\n",
            "langchain-classic 1.0.1 requires langchain-text-splitters<2.0.0,>=1.1.0, but you have langchain-text-splitters 0.0.2 which is incompatible.\n",
            "langchain-openai 1.1.6 requires langchain-core<2.0.0,>=1.2.2, but you have langchain-core 0.1.53 which is incompatible.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "shap 0.50.0 requires numpy>=2, but you have numpy 1.26.4 which is incompatible.\n",
            "langgraph-prebuilt 1.0.5 requires langchain-core>=1.0.0, but you have langchain-core 0.1.53 which is incompatible.\n",
            "xarray 2025.12.0 requires packaging>=24.1, but you have packaging 23.2 which is incompatible.\n",
            "google-adk 1.21.0 requires tenacity<10.0.0,>=9.0.0, but you have tenacity 8.5.0 which is incompatible.\n",
            "jaxlib 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "db-dtypes 1.4.4 requires packaging>=24.2.0, but you have packaging 23.2 which is incompatible.\n",
            "pytensor 2.35.1 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "jax 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "langgraph-checkpoint 3.0.1 requires langchain-core>=0.2.38, but you have langchain-core 0.1.53 which is incompatible.\n",
            "google-cloud-bigquery 3.38.0 requires packaging>=24.2.0, but you have packaging 23.2 which is incompatible.\n",
            "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed langchain-0.1.17 langchain-community-0.0.38 langchain-core-0.1.53 langchain-text-splitters-0.0.2 langsmith-0.1.147 numpy-1.26.4 packaging-23.2 tenacity-8.5.0\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "id": "b9f2597ec472486faa591a9765dae5fa",
              "pip_warning": {
                "packages": [
                  "numpy",
                  "packaging"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "ename": "ImportError",
          "evalue": "cannot import name 'LangSmithParams' from 'langchain_core.language_models.chat_models' (/usr/local/lib/python3.12/dist-packages/langchain_core/language_models/chat_models.py)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-474066299.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pip install langchain=={langchain_version}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain_openai\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mChatOpenAI\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magents\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcreate_react_agent\u001b[0m \u001b[0;31m# Reverted to common import path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magent\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAgentExecutor\u001b[0m \u001b[0;31m# Kept this specific import path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_openai/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\"\"\"Module for OpenAI integrations.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain_openai\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchat_models\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAzureChatOpenAI\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mChatOpenAI\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain_openai\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membeddings\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAzureOpenAIEmbeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOpenAIEmbeddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain_openai\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mllms\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAzureOpenAI\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOpenAI\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_openai/chat_models/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\"\"\"Module for OpenAI chat models.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain_openai\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchat_models\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mazure\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAzureChatOpenAI\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain_openai\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchat_models\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mChatOpenAI\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_openai/chat_models/azure.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mopenai\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlanguage_models\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLanguageModelInput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlanguage_models\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchat_models\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLangSmithParams\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mChatGenerationChunk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mChatResult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunnables\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRunnable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'LangSmithParams' from 'langchain_core.language_models.chat_models' (/usr/local/lib/python3.12/dist-packages/langchain_core/language_models/chat_models.py)",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "langchain_version = \"0.1.17\"\n",
        "!pip uninstall -y langchain\n",
        "!pip install langchain=={langchain_version}\n",
        "\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.agents import create_react_agent # Reverted to common import path\n",
        "from langchain.agents.agent import AgentExecutor # Kept this specific import path\n",
        "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "\n",
        "# Initialize the LLM (make sure OPENAI_API_KEY is set in environment variables)\n",
        "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
        "\n",
        "# Define the agent prompt\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", \"You are a helpful assistant that can manage and search resumes using the provided tools.\"),\n",
        "        MessagesPlaceholder(\"chat_history\"),\n",
        "        (\"human\", \"{input}\"),\n",
        "        MessagesPlaceholder(\"agent_scratchpad\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Create the ReAct agent\n",
        "agent = create_react_agent(llm, tools, prompt)\n",
        "\n",
        "# Create the AgentExecutor\n",
        "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True, handle_parsing_errors=True)\n",
        "\n",
        "print(\"âœ“ Agent and tools set up successfully.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "27439f77",
      "metadata": {
        "id": "27439f77"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous error 'ImportError: cannot import name 'LangSmithParams'' occurred because the installed `langchain-openai` version was incompatible with the downgraded `langchain-core`. I need to ensure a compatible version of `langchain-openai` is installed alongside `langchain==0.1.17`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "27d4887a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "27d4887a",
        "outputId": "a0809e14-c811-475d-cdc4-702a0684eb56"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found existing installation: langchain 0.1.17\n",
            "Uninstalling langchain-0.1.17:\n",
            "  Successfully uninstalled langchain-0.1.17\n",
            "Found existing installation: langchain-openai 1.1.6\n",
            "Uninstalling langchain-openai-1.1.6:\n",
            "  Successfully uninstalled langchain-openai-1.1.6\n",
            "Collecting langchain==0.1.17\n",
            "  Using cached langchain-0.1.17-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting langchain-openai==0.0.8\n",
            "  Downloading langchain_openai-0.0.8-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.12/dist-packages (from langchain==0.1.17) (6.0.3)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.12/dist-packages (from langchain==0.1.17) (2.0.45)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.12/dist-packages (from langchain==0.1.17) (3.13.2)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.12/dist-packages (from langchain==0.1.17) (0.6.7)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.12/dist-packages (from langchain==0.1.17) (1.33)\n",
            "Requirement already satisfied: langchain-community<0.1,>=0.0.36 in /usr/local/lib/python3.12/dist-packages (from langchain==0.1.17) (0.0.38)\n",
            "Requirement already satisfied: langchain-core<0.2.0,>=0.1.48 in /usr/local/lib/python3.12/dist-packages (from langchain==0.1.17) (0.1.53)\n",
            "Requirement already satisfied: langchain-text-splitters<0.1,>=0.0.1 in /usr/local/lib/python3.12/dist-packages (from langchain==0.1.17) (0.0.2)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /usr/local/lib/python3.12/dist-packages (from langchain==0.1.17) (0.1.147)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.12/dist-packages (from langchain==0.1.17) (1.26.4)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.12/dist-packages (from langchain==0.1.17) (2.12.3)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.12/dist-packages (from langchain==0.1.17) (2.32.5)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain==0.1.17) (8.5.0)\n",
            "Collecting openai<2.0.0,>=1.10.0 (from langchain-openai==0.0.8)\n",
            "  Downloading openai-1.109.1-py3-none-any.whl.metadata (29 kB)\n",
            "Requirement already satisfied: tiktoken<1,>=0.5.2 in /usr/local/lib/python3.12/dist-packages (from langchain-openai==0.0.8) (0.12.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.17) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.17) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.17) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.17) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.17) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.17) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.17) (1.22.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain==0.1.17) (3.26.2)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain==0.1.17) (0.9.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0,>=1.33->langchain==0.1.17) (3.0.0)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.12/dist-packages (from langchain-core<0.2.0,>=0.1.48->langchain==0.1.17) (23.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain==0.1.17) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain==0.1.17) (3.11.5)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain==0.1.17) (1.0.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.10.0->langchain-openai==0.0.8) (4.12.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.10.0->langchain-openai==0.0.8) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.10.0->langchain-openai==0.0.8) (0.12.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.10.0->langchain-openai==0.0.8) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.10.0->langchain-openai==0.0.8) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.10.0->langchain-openai==0.0.8) (4.15.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1->langchain==0.1.17) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1->langchain==0.1.17) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1->langchain==0.1.17) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain==0.1.17) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain==0.1.17) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain==0.1.17) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain==0.1.17) (2025.11.12)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3,>=1.4->langchain==0.1.17) (3.3.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken<1,>=0.5.2->langchain-openai==0.0.8) (2025.11.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain==0.1.17) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain==0.1.17) (0.16.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain==0.1.17) (1.1.0)\n",
            "Using cached langchain-0.1.17-py3-none-any.whl (867 kB)\n",
            "Downloading langchain_openai-0.0.8-py3-none-any.whl (32 kB)\n",
            "Downloading openai-1.109.1-py3-none-any.whl (948 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m948.6/948.6 kB\u001b[0m \u001b[31m58.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: openai, langchain-openai, langchain\n",
            "  Attempting uninstall: openai\n",
            "    Found existing installation: openai 2.12.0\n",
            "    Uninstalling openai-2.12.0:\n",
            "      Successfully uninstalled openai-2.12.0\n",
            "Successfully installed langchain-0.1.17 langchain-openai-0.0.8 openai-1.109.1\n"
          ]
        },
        {
          "ename": "ValidationError",
          "evalue": "1 validation error for ChatOpenAI\n__root__\n  Did not find openai_api_key, please add an environment variable `OPENAI_API_KEY` which contains it, or pass `openai_api_key` as a named parameter. (type=value_error)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValidationError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-356444887.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# Initialize the LLM (make sure OPENAI_API_KEY is set in environment variables)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mllm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mChatOpenAI\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"gpt-4o-mini\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemperature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# Define the agent prompt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pydantic/v1/main.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(__pydantic_self__, **data)\u001b[0m\n\u001b[1;32m    345\u001b[0m         \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfields_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_error\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__pydantic_self__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvalidation_error\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mvalidation_error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    348\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m             \u001b[0mobject_setattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__pydantic_self__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__dict__'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValidationError\u001b[0m: 1 validation error for ChatOpenAI\n__root__\n  Did not find openai_api_key, please add an environment variable `OPENAI_API_KEY` which contains it, or pass `openai_api_key` as a named parameter. (type=value_error)"
          ]
        }
      ],
      "source": [
        "langchain_version = \"0.1.17\"\n",
        "langchain_openai_version = \"0.0.8\"\n",
        "!pip uninstall -y langchain langchain-openai\n",
        "!pip install langchain=={langchain_version} langchain-openai=={langchain_openai_version}\n",
        "\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.agents import create_react_agent # Reverted to common import path\n",
        "from langchain.agents.agent import AgentExecutor # Kept this specific import path\n",
        "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "\n",
        "# Initialize the LLM (make sure OPENAI_API_KEY is set in environment variables)\n",
        "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
        "\n",
        "# Define the agent prompt\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", \"You are a helpful assistant that can manage and search resumes using the provided tools.\"),\n",
        "        MessagesPlaceholder(\"chat_history\"),\n",
        "        (\"human\", \"{input}\"),\n",
        "        MessagesPlaceholder(\"agent_scratchpad\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Create the ReAct agent\n",
        "agent = create_react_agent(llm, tools, prompt)\n",
        "\n",
        "# Create the AgentExecutor\n",
        "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True, handle_parsing_errors=True)\n",
        "\n",
        "print(\"âœ“ Agent and tools set up successfully.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b4d0a234",
      "metadata": {
        "id": "b4d0a234"
      },
      "source": [
        "**Reasoning**:\n",
        "The `ValidationError` indicates that `OPENAI_API_KEY` was not found when `ChatOpenAI` was initialized. This can happen if environment variables set in previous cells are not persistent across `pip uninstall` and `pip install` commands. I will ensure the `OPENAI_API_KEY` is explicitly re-loaded and set in the environment just before initializing `ChatOpenAI`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "c72dc667",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "c72dc667",
        "outputId": "b7986ab3-62e4-4f02-accd-a5f2b89741c6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found existing installation: langchain 0.1.17\n",
            "Uninstalling langchain-0.1.17:\n",
            "  Successfully uninstalled langchain-0.1.17\n",
            "Found existing installation: langchain-openai 0.0.8\n",
            "Uninstalling langchain-openai-0.0.8:\n",
            "  Successfully uninstalled langchain-openai-0.0.8\n",
            "Collecting langchain==0.1.17\n",
            "  Using cached langchain-0.1.17-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting langchain-openai==0.0.8\n",
            "  Using cached langchain_openai-0.0.8-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.12/dist-packages (from langchain==0.1.17) (6.0.3)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.12/dist-packages (from langchain==0.1.17) (2.0.45)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.12/dist-packages (from langchain==0.1.17) (3.13.2)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.12/dist-packages (from langchain==0.1.17) (0.6.7)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.12/dist-packages (from langchain==0.1.17) (1.33)\n",
            "Requirement already satisfied: langchain-community<0.1,>=0.0.36 in /usr/local/lib/python3.12/dist-packages (from langchain==0.1.17) (0.0.38)\n",
            "Requirement already satisfied: langchain-core<0.2.0,>=0.1.48 in /usr/local/lib/python3.12/dist-packages (from langchain==0.1.17) (0.1.53)\n",
            "Requirement already satisfied: langchain-text-splitters<0.1,>=0.0.1 in /usr/local/lib/python3.12/dist-packages (from langchain==0.1.17) (0.0.2)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /usr/local/lib/python3.12/dist-packages (from langchain==0.1.17) (0.1.147)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.12/dist-packages (from langchain==0.1.17) (1.26.4)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.12/dist-packages (from langchain==0.1.17) (2.12.3)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.12/dist-packages (from langchain==0.1.17) (2.32.5)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain==0.1.17) (8.5.0)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.10.0 in /usr/local/lib/python3.12/dist-packages (from langchain-openai==0.0.8) (1.109.1)\n",
            "Requirement already satisfied: tiktoken<1,>=0.5.2 in /usr/local/lib/python3.12/dist-packages (from langchain-openai==0.0.8) (0.12.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.17) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.17) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.17) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.17) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.17) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.17) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.17) (1.22.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain==0.1.17) (3.26.2)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain==0.1.17) (0.9.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0,>=1.33->langchain==0.1.17) (3.0.0)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.12/dist-packages (from langchain-core<0.2.0,>=0.1.48->langchain==0.1.17) (23.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain==0.1.17) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain==0.1.17) (3.11.5)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain==0.1.17) (1.0.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.10.0->langchain-openai==0.0.8) (4.12.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.10.0->langchain-openai==0.0.8) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.10.0->langchain-openai==0.0.8) (0.12.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.10.0->langchain-openai==0.0.8) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.10.0->langchain-openai==0.0.8) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.10.0->langchain-openai==0.0.8) (4.15.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1->langchain==0.1.17) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1->langchain==0.1.17) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1->langchain==0.1.17) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain==0.1.17) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain==0.1.17) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain==0.1.17) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain==0.1.17) (2025.11.12)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3,>=1.4->langchain==0.1.17) (3.3.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken<1,>=0.5.2->langchain-openai==0.0.8) (2025.11.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain==0.1.17) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain==0.1.17) (0.16.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain==0.1.17) (1.1.0)\n",
            "Using cached langchain-0.1.17-py3-none-any.whl (867 kB)\n",
            "Using cached langchain_openai-0.0.8-py3-none-any.whl (32 kB)\n",
            "Installing collected packages: langchain-openai, langchain\n",
            "Successfully installed langchain-0.1.17 langchain-openai-0.0.8\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "id": "0fbf86055c1949e292ceda64fb2d9b44",
              "pip_warning": {
                "packages": [
                  "langchain",
                  "langchain_openai"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "ename": "NameError",
          "evalue": "name 'tools' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3798630198.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;31m# Create the ReAct agent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m \u001b[0magent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_react_agent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mllm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtools\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;31m# Create the AgentExecutor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'tools' is not defined"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "langchain_version = \"0.1.17\"\n",
        "langchain_openai_version = \"0.0.8\"\n",
        "!pip uninstall -y langchain langchain-openai\n",
        "!pip install langchain=={langchain_version} langchain-openai=={langchain_openai_version}\n",
        "\n",
        "# Re-load API key to ensure it's available after package installations\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')\n",
        "\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.agents import create_react_agent\n",
        "from langchain.agents.agent import AgentExecutor\n",
        "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "\n",
        "# Initialize the LLM (make sure OPENAI_API_KEY is set in environment variables)\n",
        "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
        "\n",
        "# Define the agent prompt\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", \"You are a helpful assistant that can manage and search resumes using the provided tools.\"),\n",
        "        MessagesPlaceholder(\"chat_history\"),\n",
        "        (\"human\", \"{input}\"),\n",
        "        MessagesPlaceholder(\"agent_scratchpad\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Create the ReAct agent\n",
        "agent = create_react_agent(llm, tools, prompt)\n",
        "\n",
        "# Create the AgentExecutor\n",
        "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True, handle_parsing_errors=True)\n",
        "\n",
        "print(\"âœ“ Agent and tools set up successfully.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d148201e",
      "metadata": {
        "id": "d148201e"
      },
      "source": [
        "**Reasoning**:\n",
        "The `NameError: name 'tools' is not defined` occurred because the `tools` list was defined in a previous cell and was not available after reinstalling LangChain packages. To resolve this, I will include the `tools` definition and the `@tool` decorator import within the same cell that sets up the agent, ensuring all necessary components are defined before being used.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "45e33e6a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "45e33e6a",
        "outputId": "40e15256-431e-4604-a69f-8f3a28520912"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found existing installation: langchain 0.1.17\n",
            "Uninstalling langchain-0.1.17:\n",
            "  Successfully uninstalled langchain-0.1.17\n",
            "Found existing installation: langchain-openai 0.0.8\n",
            "Uninstalling langchain-openai-0.0.8:\n",
            "  Successfully uninstalled langchain-openai-0.0.8\n",
            "Collecting langchain==0.1.17\n",
            "  Using cached langchain-0.1.17-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting langchain-openai==0.0.8\n",
            "  Using cached langchain_openai-0.0.8-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.12/dist-packages (from langchain==0.1.17) (6.0.3)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.12/dist-packages (from langchain==0.1.17) (2.0.45)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.12/dist-packages (from langchain==0.1.17) (3.13.2)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.12/dist-packages (from langchain==0.1.17) (0.6.7)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.12/dist-packages (from langchain==0.1.17) (1.33)\n",
            "Requirement already satisfied: langchain-community<0.1,>=0.0.36 in /usr/local/lib/python3.12/dist-packages (from langchain==0.1.17) (0.0.38)\n",
            "Requirement already satisfied: langchain-core<0.2.0,>=0.1.48 in /usr/local/lib/python3.12/dist-packages (from langchain==0.1.17) (0.1.53)\n",
            "Requirement already satisfied: langchain-text-splitters<0.1,>=0.0.1 in /usr/local/lib/python3.12/dist-packages (from langchain==0.1.17) (0.0.2)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /usr/local/lib/python3.12/dist-packages (from langchain==0.1.17) (0.1.147)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.12/dist-packages (from langchain==0.1.17) (1.26.4)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.12/dist-packages (from langchain==0.1.17) (2.12.3)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.12/dist-packages (from langchain==0.1.17) (2.32.5)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain==0.1.17) (8.5.0)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.10.0 in /usr/local/lib/python3.12/dist-packages (from langchain-openai==0.0.8) (1.109.1)\n",
            "Requirement already satisfied: tiktoken<1,>=0.5.2 in /usr/local/lib/python3.12/dist-packages (from langchain-openai==0.0.8) (0.12.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.17) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.17) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.17) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.17) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.17) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.17) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.17) (1.22.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain==0.1.17) (3.26.2)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain==0.1.17) (0.9.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0,>=1.33->langchain==0.1.17) (3.0.0)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.12/dist-packages (from langchain-core<0.2.0,>=0.1.48->langchain==0.1.17) (23.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain==0.1.17) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain==0.1.17) (3.11.5)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain==0.1.17) (1.0.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.10.0->langchain-openai==0.0.8) (4.12.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.10.0->langchain-openai==0.0.8) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.10.0->langchain-openai==0.0.8) (0.12.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.10.0->langchain-openai==0.0.8) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.10.0->langchain-openai==0.0.8) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.10.0->langchain-openai==0.0.8) (4.15.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1->langchain==0.1.17) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1->langchain==0.1.17) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1->langchain==0.1.17) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain==0.1.17) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain==0.1.17) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain==0.1.17) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain==0.1.17) (2025.11.12)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3,>=1.4->langchain==0.1.17) (3.3.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken<1,>=0.5.2->langchain-openai==0.0.8) (2025.11.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain==0.1.17) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain==0.1.17) (0.16.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain==0.1.17) (1.1.0)\n",
            "Using cached langchain-0.1.17-py3-none-any.whl (867 kB)\n",
            "Using cached langchain_openai-0.0.8-py3-none-any.whl (32 kB)\n",
            "Installing collected packages: langchain-openai, langchain\n",
            "Successfully installed langchain-0.1.17 langchain-openai-0.0.8\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "Prompt missing required variables: {'tool_names', 'tools'}",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-203430156.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;31m# Create the ReAct agent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m \u001b[0magent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_react_agent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mllm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtools\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;31m# Create the AgentExecutor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain/agents/react/agent.py\u001b[0m in \u001b[0;36mcreate_react_agent\u001b[0;34m(llm, tools, prompt, output_parser, tools_renderer, stop_sequence)\u001b[0m\n\u001b[1;32m    112\u001b[0m     )\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmissing_vars\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Prompt missing required variables: {missing_vars}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     prompt = prompt.partial(\n",
            "\u001b[0;31mValueError\u001b[0m: Prompt missing required variables: {'tool_names', 'tools'}"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "langchain_version = \"0.1.17\"\n",
        "langchain_openai_version = \"0.0.8\"\n",
        "!pip uninstall -y langchain langchain-openai\n",
        "!pip install langchain=={langchain_version} langchain-openai=={langchain_openai_version}\n",
        "\n",
        "# Re-load API key to ensure it's available after package installations\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')\n",
        "\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.agents import create_react_agent\n",
        "from langchain.agents.agent import AgentExecutor\n",
        "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "from langchain.tools import tool\n",
        "\n",
        "# Wrap the existing functions as tools\n",
        "\n",
        "@tool\n",
        "def ingest_resumes_tool():\n",
        "    \"\"\"Ingest new resumes from the './resumes' folder into the vector database. Use this tool when new resumes need to be processed or the database needs to be updated.\"\"\"\n",
        "    return ingest_resumes()\n",
        "\n",
        "@tool\n",
        "def list_resumes_tool():\n",
        "    \"\"\"List all the unique resume file names currently stored in the vector database. Use this tool to see what resumes have been ingested.\"\"\"\n",
        "    return list_resumes()\n",
        "\n",
        "@tool\n",
        "def search_resumes_tool(skills: str):\n",
        "    \"\"\"Search for candidates whose resumes match the given skills. Input should be a comma-separated string of required skills (e.g., 'Python, Machine Learning, Docker'). Use this tool to find candidates for a job opening.\"\"\"\n",
        "    return search_resumes(skills)\n",
        "\n",
        "@tool\n",
        "def clear_resumes_tool():\n",
        "    \"\"\"Clear all resumes from the vector database. This will delete the entire resume database. Use this tool to start fresh or remove all stored resume data.\"\"\"\n",
        "    return clear_resumes()\n",
        "\n",
        "# Create a list of all available tools\n",
        "tools = [\n",
        "    ingest_resumes_tool,\n",
        "    list_resumes_tool,\n",
        "    search_resumes_tool,\n",
        "    clear_resumes_tool\n",
        "]\n",
        "\n",
        "# Initialize the LLM (make sure OPENAI_API_KEY is set in environment variables)\n",
        "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
        "\n",
        "# Define the agent prompt\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", \"You are a helpful assistant that can manage and search resumes using the provided tools.\"),\n",
        "        MessagesPlaceholder(\"chat_history\"),\n",
        "        (\"human\", \"{input}\"),\n",
        "        MessagesPlaceholder(\"agent_scratchpad\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Create the ReAct agent\n",
        "agent = create_react_agent(llm, tools, prompt)\n",
        "\n",
        "# Create the AgentExecutor\n",
        "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True, handle_parsing_errors=True)\n",
        "\n",
        "print(\"âœ“ Agent and tools set up successfully.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "540aaf9d",
      "metadata": {
        "id": "540aaf9d"
      },
      "source": [
        "**Reasoning**:\n",
        "The `ValueError` indicated that the `ChatPromptTemplate` was missing expected variables `tools` and `tool_names` required by `create_react_agent`. To fix this, I will modify the system message within the `ChatPromptTemplate` to explicitly include these placeholders, following a standard ReAct prompt structure.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "7c707c1f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "7c707c1f",
        "outputId": "433fcdf5-b133-42d9-a9ae-535d220a5f61"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found existing installation: langchain 0.1.17\n",
            "Uninstalling langchain-0.1.17:\n",
            "  Successfully uninstalled langchain-0.1.17\n",
            "Found existing installation: langchain-openai 0.0.8\n",
            "Uninstalling langchain-openai-0.0.8:\n",
            "  Successfully uninstalled langchain-openai-0.0.8\n",
            "Collecting langchain==0.1.17\n",
            "  Using cached langchain-0.1.17-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting langchain-openai==0.0.8\n",
            "  Using cached langchain_openai-0.0.8-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.12/dist-packages (from langchain==0.1.17) (6.0.3)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.12/dist-packages (from langchain==0.1.17) (2.0.45)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.12/dist-packages (from langchain==0.1.17) (3.13.2)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.12/dist-packages (from langchain==0.1.17) (0.6.7)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.12/dist-packages (from langchain==0.1.17) (1.33)\n",
            "Requirement already satisfied: langchain-community<0.1,>=0.0.36 in /usr/local/lib/python3.12/dist-packages (from langchain==0.1.17) (0.0.38)\n",
            "Requirement already satisfied: langchain-core<0.2.0,>=0.1.48 in /usr/local/lib/python3.12/dist-packages (from langchain==0.1.17) (0.1.53)\n",
            "Requirement already satisfied: langchain-text-splitters<0.1,>=0.0.1 in /usr/local/lib/python3.12/dist-packages (from langchain==0.1.17) (0.0.2)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /usr/local/lib/python3.12/dist-packages (from langchain==0.1.17) (0.1.147)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.12/dist-packages (from langchain==0.1.17) (1.26.4)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.12/dist-packages (from langchain==0.1.17) (2.12.3)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.12/dist-packages (from langchain==0.1.17) (2.32.5)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain==0.1.17) (8.5.0)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.10.0 in /usr/local/lib/python3.12/dist-packages (from langchain-openai==0.0.8) (1.109.1)\n",
            "Requirement already satisfied: tiktoken<1,>=0.5.2 in /usr/local/lib/python3.12/dist-packages (from langchain-openai==0.0.8) (0.12.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.17) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.17) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.17) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.17) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.17) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.17) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.17) (1.22.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain==0.1.17) (3.26.2)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain==0.1.17) (0.9.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0,>=1.33->langchain==0.1.17) (3.0.0)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.12/dist-packages (from langchain-core<0.2.0,>=0.1.48->langchain==0.1.17) (23.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain==0.1.17) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain==0.1.17) (3.11.5)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain==0.1.17) (1.0.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.10.0->langchain-openai==0.0.8) (4.12.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.10.0->langchain-openai==0.0.8) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.10.0->langchain-openai==0.0.8) (0.12.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.10.0->langchain-openai==0.0.8) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.10.0->langchain-openai==0.0.8) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.10.0->langchain-openai==0.0.8) (4.15.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1->langchain==0.1.17) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1->langchain==0.1.17) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1->langchain==0.1.17) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain==0.1.17) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain==0.1.17) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain==0.1.17) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain==0.1.17) (2025.11.12)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3,>=1.4->langchain==0.1.17) (3.3.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken<1,>=0.5.2->langchain-openai==0.0.8) (2025.11.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain==0.1.17) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain==0.1.17) (0.16.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain==0.1.17) (1.1.0)\n",
            "Using cached langchain-0.1.17-py3-none-any.whl (867 kB)\n",
            "Using cached langchain_openai-0.0.8-py3-none-any.whl (32 kB)\n",
            "Installing collected packages: langchain-openai, langchain\n",
            "Successfully installed langchain-0.1.17 langchain-openai-0.0.8\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "id": "83f0345edbcd4175a54a16d53513a934",
              "pip_warning": {
                "packages": [
                  "langchain",
                  "langchain_openai"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ“ Agent and tools set up successfully.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "langchain_version = \"0.1.17\"\n",
        "langchain_openai_version = \"0.0.8\"\n",
        "!pip uninstall -y langchain langchain-openai\n",
        "!pip install langchain=={langchain_version} langchain-openai=={langchain_openai_version}\n",
        "\n",
        "# Re-load API key to ensure it's available after package installations\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')\n",
        "\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.agents import create_react_agent\n",
        "from langchain.agents.agent import AgentExecutor\n",
        "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "from langchain.tools import tool\n",
        "\n",
        "# Wrap the existing functions as tools\n",
        "\n",
        "@tool\n",
        "def ingest_resumes_tool():\n",
        "    \"\"\"Ingest new resumes from the './resumes' folder into the vector database. Use this tool when new resumes need to be processed or the database needs to be updated.\"\"\"\n",
        "    return ingest_resumes()\n",
        "\n",
        "@tool\n",
        "def list_resumes_tool():\n",
        "    \"\"\"List all the unique resume file names currently stored in the vector database. Use this tool to see what resumes have been ingested.\"\"\"\n",
        "    return list_resumes()\n",
        "\n",
        "@tool\n",
        "def search_resumes_tool(skills: str):\n",
        "    \"\"\"Search for candidates whose resumes match the given skills. Input should be a comma-separated string of required skills (e.g., 'Python, Machine Learning, Docker'). Use this tool to find candidates for a job opening.\"\"\"\n",
        "    return search_resumes(skills)\n",
        "\n",
        "@tool\n",
        "def clear_resumes_tool():\n",
        "    \"\"\"Clear all resumes from the vector database. This will delete the entire resume database. Use this tool to start fresh or remove all stored resume data.\"\"\"\n",
        "    return clear_resumes()\n",
        "\n",
        "# Create a list of all available tools\n",
        "tools = [\n",
        "    ingest_resumes_tool,\n",
        "    list_resumes_tool,\n",
        "    search_resumes_tool,\n",
        "    clear_resumes_tool\n",
        "]\n",
        "\n",
        "# Initialize the LLM (make sure OPENAI_API_KEY is set in environment variables)\n",
        "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
        "\n",
        "# Define the agent prompt with explicit tools and tool_names placeholders\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\n",
        "            \"system\",\n",
        "            \"You are a helpful assistant that can manage and search resumes using the provided tools.\\n\"\n",
        "            \"You have access to the following tools:\\n\"\n",
        "            \"{tools}\\n\"\n",
        "            \"Use the following format:\\n\"\n",
        "            \"Question: the input question you must answer\\n\"\n",
        "            \"Thought: you should always think about what to do\\n\"\n",
        "            \"Action: the action to take, should be one of [{tool_names}]\\n\"\n",
        "            \"Action Input: the input to the action\\n\"\n",
        "            \"Observation: the result of the action\\n\"\n",
        "            \"... (this Thought/Action/Action Input/Observation can repeat N times)\\n\"\n",
        "            \"Thought: I now know the final answer\\n\"\n",
        "            \"Final Answer: the final answer to the original input question\"\n",
        "        ),\n",
        "        MessagesPlaceholder(\"chat_history\"),\n",
        "        (\"human\", \"{input}\"),\n",
        "        MessagesPlaceholder(\"agent_scratchpad\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Create the ReAct agent\n",
        "agent = create_react_agent(llm, tools, prompt)\n",
        "\n",
        "# Create the AgentExecutor\n",
        "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True, handle_parsing_errors=True)\n",
        "\n",
        "print(\"âœ“ Agent and tools set up successfully.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "07909b1d",
      "metadata": {
        "id": "07909b1d"
      },
      "source": [
        "## execute_cell_f79043b7\n",
        "\n",
        "### Subtask:\n",
        "Execute the modified cell `f79043b7` to set up the agent with the specified LangChain version.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "696b8ef3",
      "metadata": {
        "id": "696b8ef3"
      },
      "source": [
        "**Reasoning**:\n",
        "The subtask requires executing the modified cell `7c707c1f` to properly set up the agent and tools, ensuring `agent_executor` is defined for subsequent steps. This is the last step in setting up the agent.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "1e88e342",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "1e88e342",
        "outputId": "b699e4e5-4579-40cd-b100-6c9e7e424a8f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found existing installation: langchain 0.1.17\n",
            "Uninstalling langchain-0.1.17:\n",
            "  Successfully uninstalled langchain-0.1.17\n",
            "Found existing installation: langchain-openai 0.0.8\n",
            "Uninstalling langchain-openai-0.0.8:\n",
            "  Successfully uninstalled langchain-openai-0.0.8\n",
            "Collecting langchain==0.1.17\n",
            "  Using cached langchain-0.1.17-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting langchain-openai==0.0.8\n",
            "  Using cached langchain_openai-0.0.8-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.12/dist-packages (from langchain==0.1.17) (6.0.3)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.12/dist-packages (from langchain==0.1.17) (2.0.45)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.12/dist-packages (from langchain==0.1.17) (3.13.2)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.12/dist-packages (from langchain==0.1.17) (0.6.7)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.12/dist-packages (from langchain==0.1.17) (1.33)\n",
            "Requirement already satisfied: langchain-community<0.1,>=0.0.36 in /usr/local/lib/python3.12/dist-packages (from langchain==0.1.17) (0.0.38)\n",
            "Requirement already satisfied: langchain-core<0.2.0,>=0.1.48 in /usr/local/lib/python3.12/dist-packages (from langchain==0.1.17) (0.1.53)\n",
            "Requirement already satisfied: langchain-text-splitters<0.1,>=0.0.1 in /usr/local/lib/python3.12/dist-packages (from langchain==0.1.17) (0.0.2)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /usr/local/lib/python3.12/dist-packages (from langchain==0.1.17) (0.1.147)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.12/dist-packages (from langchain==0.1.17) (1.26.4)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.12/dist-packages (from langchain==0.1.17) (2.12.3)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.12/dist-packages (from langchain==0.1.17) (2.32.5)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain==0.1.17) (8.5.0)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.10.0 in /usr/local/lib/python3.12/dist-packages (from langchain-openai==0.0.8) (1.109.1)\n",
            "Requirement already satisfied: tiktoken<1,>=0.5.2 in /usr/local/lib/python3.12/dist-packages (from langchain-openai==0.0.8) (0.12.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.17) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.17) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.17) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.17) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.17) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.17) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.17) (1.22.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain==0.1.17) (3.26.2)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain==0.1.17) (0.9.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0,>=1.33->langchain==0.1.17) (3.0.0)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.12/dist-packages (from langchain-core<0.2.0,>=0.1.48->langchain==0.1.17) (23.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain==0.1.17) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain==0.1.17) (3.11.5)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain==0.1.17) (1.0.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.10.0->langchain-openai==0.0.8) (4.12.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.10.0->langchain-openai==0.0.8) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.10.0->langchain-openai==0.0.8) (0.12.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.10.0->langchain-openai==0.0.8) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.10.0->langchain-openai==0.0.8) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.10.0->langchain-openai==0.0.8) (4.15.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1->langchain==0.1.17) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1->langchain==0.1.17) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1->langchain==0.1.17) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain==0.1.17) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain==0.1.17) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain==0.1.17) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain==0.1.17) (2025.11.12)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3,>=1.4->langchain==0.1.17) (3.3.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken<1,>=0.5.2->langchain-openai==0.0.8) (2025.11.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain==0.1.17) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain==0.1.17) (0.16.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain==0.1.17) (1.1.0)\n",
            "Using cached langchain-0.1.17-py3-none-any.whl (867 kB)\n",
            "Using cached langchain_openai-0.0.8-py3-none-any.whl (32 kB)\n",
            "Installing collected packages: langchain-openai, langchain\n",
            "Successfully installed langchain-0.1.17 langchain-openai-0.0.8\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "id": "076ba8844fdf4cd2b559056099bb4de7",
              "pip_warning": {
                "packages": [
                  "langchain",
                  "langchain_openai"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ“ Agent and tools set up successfully.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "langchain_version = \"0.1.17\"\n",
        "langchain_openai_version = \"0.0.8\"\n",
        "!pip uninstall -y langchain langchain-openai\n",
        "!pip install langchain=={langchain_version} langchain-openai=={langchain_openai_version}\n",
        "\n",
        "# Re-load API key to ensure it's available after package installations\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')\n",
        "\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.agents import create_react_agent\n",
        "from langchain.agents.agent import AgentExecutor\n",
        "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "from langchain.tools import tool\n",
        "\n",
        "# Wrap the existing functions as tools\n",
        "\n",
        "@tool\n",
        "def ingest_resumes_tool():\n",
        "    \"\"\"Ingest new resumes from the './resumes' folder into the vector database. Use this tool when new resumes need to be processed or the database needs to be updated.\"\"\"\n",
        "    return ingest_resumes()\n",
        "\n",
        "@tool\n",
        "def list_resumes_tool():\n",
        "    \"\"\"List all the unique resume file names currently stored in the vector database. Use this tool to see what resumes have been ingested.\"\"\"\n",
        "    return list_resumes()\n",
        "\n",
        "@tool\n",
        "def search_resumes_tool(skills: str):\n",
        "    \"\"\"Search for candidates whose resumes match the given skills. Input should be a comma-separated string of required skills (e.g., 'Python, Machine Learning, Docker'). Use this tool to find candidates for a job opening.\"\"\"\n",
        "    return search_resumes(skills)\n",
        "\n",
        "@tool\n",
        "def clear_resumes_tool():\n",
        "    \"\"\"Clear all resumes from the vector database. This will delete the entire resume database. Use this tool to start fresh or remove all stored resume data.\"\"\"\n",
        "    return clear_resumes()\n",
        "\n",
        "# Create a list of all available tools\n",
        "tools = [\n",
        "    ingest_resumes_tool,\n",
        "    list_resumes_tool,\n",
        "    search_resumes_tool,\n",
        "    clear_resumes_tool\n",
        "]\n",
        "\n",
        "# Initialize the LLM (make sure OPENAI_API_KEY is set in environment variables)\n",
        "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
        "\n",
        "# Define the agent prompt with explicit tools and tool_names placeholders\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\n",
        "            \"system\",\n",
        "            \"You are a helpful assistant that can manage and search resumes using the provided tools.\\n\"\n",
        "            \"You have access to the following tools:\\n\"\n",
        "            \"{tools}\\n\"\n",
        "            \"Use the following format:\\n\"\n",
        "            \"Question: the input question you must answer\\n\"\n",
        "            \"Thought: you should always think about what to do\\n\"\n",
        "            \"Action: the action to take, should be one of [{tool_names}]\\n\"\n",
        "            \"Action Input: the input to the action\\n\"\n",
        "            \"Observation: the result of the action\\n\"\n",
        "            \"... (this Thought/Action/Action Input/Observation can repeat N times)\\n\"\n",
        "            \"Thought: I now know the final answer\\n\"\n",
        "            \"Final Answer: the final answer to the original input question\"\n",
        "        ),\n",
        "        MessagesPlaceholder(\"chat_history\"),\n",
        "        (\"human\", \"{input}\"),\n",
        "        MessagesPlaceholder(\"agent_scratchpad\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Create the ReAct agent\n",
        "agent = create_react_agent(llm, tools, prompt)\n",
        "\n",
        "# Create the AgentExecutor\n",
        "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True, handle_parsing_errors=True)\n",
        "\n",
        "print(\"âœ“ Agent and tools set up successfully.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "edab57a5",
      "metadata": {
        "id": "edab57a5"
      },
      "source": [
        "## execute_cell_e23d1f0d\n",
        "\n",
        "### Subtask:\n",
        "Test the agent with example queries.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b9fba140",
      "metadata": {
        "id": "b9fba140"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Q&A\n",
        "The agent was successfully set up with the specified LangChain version and tools. However, the provided process did not include testing the agent with example queries.\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "*   The LangChain environment was successfully configured by installing `langchain==0.1.17` and `langchain-openai==0.0.8`, resolving initial compatibility issues.\n",
        "*   Several challenges were overcome during the setup, including `ImportError` due to package version conflicts, `ValidationError` from `OPENAI_API_KEY` not being persistently loaded, `NameError` because tools were not defined in scope, and `ValueError` due to a missing prompt template variables (`tools`, `tool_names`).\n",
        "*   Four custom toolsâ€”`ingest_resumes_tool`, `list_resumes_tool`, `search_resumes_tool`, and `clear_resumes_tool`â€”were defined using the `@tool` decorator and successfully integrated into the agent's environment.\n",
        "*   A ReAct agent and an `AgentExecutor` were successfully initialized using `gpt-4o-mini` as the Large Language Model and the defined set of tools.\n",
        "\n",
        "### Insights or Next Steps\n",
        "*   The agent is now fully configured and ready to be interacted with. The next crucial step is to test its functionality thoroughly using diverse example queries to ensure it utilizes the tools correctly and responds as expected.\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
