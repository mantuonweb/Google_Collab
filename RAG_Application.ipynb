{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mantuonweb/Google_Collab/blob/master/RAG_Application.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c1d7dfbc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "c1d7dfbc",
        "outputId": "ee784d45-c6f9-45ca-ae17-565c310e9475"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.12/dist-packages (1.2.0)\n",
            "Collecting langchain-openai\n",
            "  Downloading langchain_openai-1.1.6-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting langchain-community\n",
            "  Downloading langchain_community-0.4.1-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting langchain-text-splitters\n",
            "  Downloading langchain_text_splitters-1.1.0-py3-none-any.whl.metadata (2.7 kB)\n",
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.13.2-cp310-abi3-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (7.6 kB)\n",
            "Collecting pypdf\n",
            "  Downloading pypdf-6.5.0-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.12/dist-packages (1.2.1)\n",
            "Requirement already satisfied: langchain-core<2.0.0,>=1.2.1 in /usr/local/lib/python3.12/dist-packages (from langchain) (1.2.1)\n",
            "Requirement already satisfied: langgraph<1.1.0,>=1.0.2 in /usr/local/lib/python3.12/dist-packages (from langchain) (1.0.5)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.12.3)\n",
            "Collecting langchain-core<2.0.0,>=1.2.1 (from langchain)\n",
            "  Downloading langchain_core-1.2.5-py3-none-any.whl.metadata (3.7 kB)\n",
            "Requirement already satisfied: openai<3.0.0,>=1.109.1 in /usr/local/lib/python3.12/dist-packages (from langchain-openai) (2.12.0)\n",
            "Requirement already satisfied: tiktoken<1.0.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-openai) (0.12.0)\n",
            "Collecting langchain-classic<2.0.0,>=1.0.0 (from langchain-community)\n",
            "  Downloading langchain_classic-1.0.1-py3-none-any.whl.metadata (4.2 kB)\n",
            "Requirement already satisfied: SQLAlchemy<3.0.0,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.0.45)\n",
            "Collecting requests<3.0.0,>=2.32.5 (from langchain-community)\n",
            "  Downloading requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: PyYAML<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (6.0.3)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (3.13.2)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (9.1.2)\n",
            "Collecting dataclasses-json<0.7.0,>=0.6.7 (from langchain-community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.12.0)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.1.125 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.4.59)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.4.3)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from faiss-cpu) (25.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.22.0)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7.0,>=0.6.7->langchain-community)\n",
            "  Downloading marshmallow-3.26.2-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7.0,>=0.6.7->langchain-community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.1->langchain) (1.33)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.1->langchain) (4.15.0)\n",
            "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.1->langchain) (0.12.0)\n",
            "Requirement already satisfied: langgraph-checkpoint<4.0.0,>=2.1.0 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.2->langchain) (3.0.1)\n",
            "Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.2 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.2->langchain) (1.0.5)\n",
            "Requirement already satisfied: langgraph-sdk<0.4.0,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.2->langchain) (0.3.0)\n",
            "Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.2->langchain) (3.6.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (3.11.5)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (0.25.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (4.12.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.10.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (0.12.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (4.67.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain-community) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain-community) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain-community) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain-community) (2025.11.12)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3.0.0,>=1.4.0->langchain-community) (3.3.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken<1.0.0,>=0.7.0->langchain-openai) (2025.11.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.2.1->langchain) (3.0.0)\n",
            "Requirement already satisfied: ormsgpack>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from langgraph-checkpoint<4.0.0,>=2.1.0->langgraph<1.1.0,>=1.0.2->langchain) (1.12.1)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain-community)\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Downloading langchain_openai-1.1.6-py3-none-any.whl (84 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m84.7/84.7 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_community-0.4.1-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m32.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_text_splitters-1.1.0-py3-none-any.whl (34 kB)\n",
            "Downloading faiss_cpu-1.13.2-cp310-abi3-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (23.8 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m23.8/23.8 MB\u001b[0m \u001b[31m30.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pypdf-6.5.0-py3-none-any.whl (329 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m329.6/329.6 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading langchain_classic-1.0.1-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_core-1.2.5-py3-none-any.whl (484 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m484.9/484.9 kB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading requests-2.32.5-py3-none-any.whl (64 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading marshmallow-3.26.2-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m51.0/51.0 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Installing collected packages: requests, pypdf, mypy-extensions, marshmallow, faiss-cpu, typing-inspect, dataclasses-json, langchain-core, langchain-text-splitters, langchain-openai, langchain-classic, langchain-community\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.32.4\n",
            "    Uninstalling requests-2.32.4:\n",
            "      Successfully uninstalled requests-2.32.4\n",
            "  Attempting uninstall: langchain-core\n",
            "    Found existing installation: langchain-core 1.2.1\n",
            "    Uninstalling langchain-core-1.2.1:\n",
            "      Successfully uninstalled langchain-core-1.2.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed dataclasses-json-0.6.7 faiss-cpu-1.13.2 langchain-classic-1.0.1 langchain-community-0.4.1 langchain-core-1.2.5 langchain-openai-1.1.6 langchain-text-splitters-1.1.0 marshmallow-3.26.2 mypy-extensions-1.1.0 pypdf-6.5.0 requests-2.32.5 typing-inspect-0.9.0\n"
          ]
        }
      ],
      "source": [
        "# Install required packages\n",
        "# Install required packages\n",
        "%pip install langchain langchain-openai langchain-community langchain-text-splitters faiss-cpu pypdf python-dotenv\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c2a7b4a1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c2a7b4a1",
        "outputId": "5289c409-2ad5-48d8-d053-2b5f95a1a50b",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ“ Successfully created 4 sample text documents!\n",
            "\n",
            "Files created in 'documents' folder:\n",
            "1. python_basics.txt\n",
            "2. ai_intro.txt\n",
            "3. company_policy.txt\n",
            "4. product_info.txt\n",
            "5. india.constitution.txt\n",
            "\n",
            "Total files: 5\n",
            "  - company_policy.txt (439 bytes)\n",
            "  - ai_intro.txt (402 bytes)\n",
            "  - product_info.txt (275 bytes)\n",
            "  - python_basics.txt (404 bytes)\n",
            "  - india.constitution.txt (2094 bytes)\n"
          ]
        }
      ],
      "source": [
        "# Create sample text documents\n",
        "import os\n",
        "\n",
        "# Create documents folder if it doesn't exist\n",
        "os.makedirs(\"documents\", exist_ok=True)\n",
        "\n",
        "# Sample TXT file 1 - Python Basics\n",
        "with open(\"documents/python_basics.txt\", \"w\") as f:\n",
        "    f.write(\"\"\"Python Programming Basics\n",
        "\n",
        "Python is a high-level programming language. It was created by Guido van Rossum in 1991.\n",
        "Python is known for its simple syntax and readability. It uses indentation to define code blocks.\n",
        "Popular uses include web development, data science, and automation.\n",
        "\n",
        "Key Features:\n",
        "- Easy to learn and read\n",
        "- Large standard library\n",
        "- Cross-platform compatibility\n",
        "- Strong community support\"\"\")\n",
        "\n",
        "# Sample TXT file 2 - AI Introduction\n",
        "with open(\"documents/ai_intro.txt\", \"w\") as f:\n",
        "    f.write(\"\"\"Introduction to Artificial Intelligence\n",
        "\n",
        "AI is the simulation of human intelligence by machines. Machine learning is a subset of AI.\n",
        "Deep learning uses neural networks with multiple layers.\n",
        "\n",
        "Common AI Applications:\n",
        "- Chatbots and virtual assistants\n",
        "- Image and speech recognition\n",
        "- Recommendation systems\n",
        "- Autonomous vehicles\n",
        "\n",
        "AI has transformed industries like healthcare, finance, and entertainment.\"\"\")\n",
        "\n",
        "# Sample TXT file 3 - Company Policy\n",
        "with open(\"documents/company_policy.txt\", \"w\") as f:\n",
        "    f.write(\"\"\"Company Remote Work Policy\n",
        "\n",
        "Effective Date: January 2024\n",
        "\n",
        "Remote Work Guidelines:\n",
        "- Employees can work remotely up to 3 days per week\n",
        "- Core hours are 10 AM to 3 PM local time\n",
        "- All team meetings must be scheduled during core hours\n",
        "- Use Slack for daily communication\n",
        "- Submit timesheets every Friday by 5 PM\n",
        "\n",
        "Equipment:\n",
        "- Company provides laptop and monitor\n",
        "- Internet stipend of $50 per month\n",
        "\n",
        "Contact HR for questions about this policy.\"\"\")\n",
        "\n",
        "# Sample TXT file 4 - Product Info\n",
        "with open(\"documents/product_info.txt\", \"w\") as f:\n",
        "    f.write(\"\"\"Product Information - SmartWatch Pro\n",
        "\n",
        "Price: $299\n",
        "Release Date: March 2024\n",
        "\n",
        "Features:\n",
        "- Heart rate monitoring\n",
        "- GPS tracking\n",
        "- 7-day battery life\n",
        "- Water resistant up to 50 meters\n",
        "- Compatible with iOS and Android\n",
        "\n",
        "Warranty: 2 years\n",
        "Colors available: Black, Silver, Rose Gold\"\"\")\n",
        "\n",
        "with open(\"documents/india.constitution.txt\", \"w\") as f:\n",
        "    f.write(\"\"\"The Constitution of India is the supreme law of the Republic of India, serving as the legal framework for the country's governance, citizen rights, and state duties.\n",
        "Basic Facts\n",
        "Adoption Date: November 26, 1949.\n",
        "Enforcement Date: January 26, 1950 (celebrated as Republic Day).\n",
        "Status: The longest written national constitution in the world.\n",
        "Current Structure (as of 2025): Approximately 448 articles in 25 parts and 12 schedules.\n",
        "Core Principles (The Preamble)\n",
        "The Preamble declares India to be a Sovereign, Socialist, Secular, Democratic Republic. It aims to secure for all citizens:\n",
        "Justice: Social, economic, and political.\n",
        "Liberty: Of thought, expression, belief, faith, and worship.\n",
        "Equality: Of status and opportunity.\n",
        "Fraternity: Assuring the dignity of the individual and national unity.\n",
        "Salient Features\n",
        "Parliamentary Democracy: Opts for the British-style parliamentary system with an elected head of state (President) and a Prime Minister as head of government.\n",
        "Federal Structure with Unitary Bias: Power is shared between the Union and States, but the Central government holds significant power during emergencies.\n",
        "Fundamental Rights: Six essential rights (Articles 12-35) protecting individual freedoms, including equality, freedom of speech, and protection against exploitation.\n",
        "Directive Principles of State Policy: Non-enforceable guidelines for the government to ensure social and economic welfare.\n",
        "Fundamental Duties: 11 duties for citizens added via the 42nd Amendment, such as respecting the National Flag and protecting the environment.\n",
        "Independent Judiciary: A single integrated judicial system with the Supreme Court at the top, possessing the power of judicial review.\n",
        "Universal Adult Franchise: Every citizen over 18 years of age has the right to vote without discrimination.\n",
        "Single Citizenship: All Indians share a single national citizenship regardless of their state.\n",
        "The \"Basic Structure\" Doctrine\n",
        "The Supreme Court (Kesavananda Bharati case) established that certain core featuresâ€”like secularism and democracyâ€”cannot be removed by any parliamentary amendment. \"\"\")\n",
        "\n",
        "print(\"âœ“ Successfully created 4 sample text documents!\")\n",
        "print(\"\\nFiles created in 'documents' folder:\")\n",
        "print(\"1. python_basics.txt\")\n",
        "print(\"2. ai_intro.txt\")\n",
        "print(\"3. company_policy.txt\")\n",
        "print(\"4. product_info.txt\")\n",
        "print(\"5. india.constitution.txt\")\n",
        "\n",
        "# List files to verify\n",
        "files = os.listdir(\"documents\")\n",
        "print(f\"\\nTotal files: {len(files)}\")\n",
        "for file in files:\n",
        "    size = os.path.getsize(f\"documents/{file}\")\n",
        "    print(f\"  - {file} ({size} bytes)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "21841da5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "21841da5",
        "outputId": "503b749c-da3d-4470-8a92-3dfc9516959b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:torchao.kernel.intmm:Warning: Detected no triton, on systems without Triton certain kernels will not work\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "API Key: sk-proj-2D_k1B8OV3MW...\n",
            "âœ“ Loaded 5 documents and created embeddings\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from langchain_community.document_loaders import TextLoader, DirectoryLoader\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from dotenv import load_dotenv\n",
        "from google.colab import userdata\n",
        "\n",
        "# Set your OpenAI API key\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')\n",
        "load_dotenv()\n",
        "print(\"API Key:\", os.environ.get(\"OPENAI_API_KEY\", \"Not set\")[:20] + \"...\")\n",
        "\n",
        "# 1. Load documents from folder\n",
        "def load_documents(folder_path):\n",
        "    txt_loader = DirectoryLoader(folder_path, glob=\"**/*.txt\", loader_cls=TextLoader)\n",
        "    txt_docs = txt_loader.load()\n",
        "    return txt_docs\n",
        "\n",
        "# 2. Create embeddings and save to FAISS\n",
        "def create_vector_store(documents, save_path=\"faiss_index\"):\n",
        "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
        "    chunks = text_splitter.split_documents(documents)\n",
        "\n",
        "    embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
        "    vectorstore = FAISS.from_documents(chunks, embeddings)\n",
        "    vectorstore.save_local(save_path)\n",
        "\n",
        "    return vectorstore\n",
        "\n",
        "# 3. Load existing vector store\n",
        "def load_vector_store(save_path=\"faiss_index\"):\n",
        "    embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
        "    vectorstore = FAISS.load_local(save_path, embeddings, allow_dangerous_deserialization=True)\n",
        "    return vectorstore\n",
        "\n",
        "# 4. Query and generate response (simplified)\n",
        "def query_documents(vectorstore, query):\n",
        "    try:\n",
        "        # Retrieve relevant documents\n",
        "        retriever = vectorstore.as_retriever(search_kwargs={\"k\": 3})\n",
        "        docs = retriever.invoke(query)\n",
        "\n",
        "        # Create context from documents\n",
        "        context = \"\\n\\n\".join([doc.page_content for doc in docs])\n",
        "\n",
        "        # Create prompt\n",
        "        prompt = f\"\"\"Answer the question based on the following context:\n",
        "\n",
        "Context:\n",
        "{context}\n",
        "\n",
        "Question: {query}\n",
        "\n",
        "Answer:\"\"\"\n",
        "\n",
        "        # Get response from LLM\n",
        "        llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
        "        response = llm.invoke(prompt)\n",
        "\n",
        "        return response.content, docs\n",
        "    except Exception as e:\n",
        "        print(f\"Error during document query: {e}\")\n",
        "        return \"An error occurred while trying to answer your question. Please try again.\", []\n",
        "\n",
        "# Load and create vector store\n",
        "folder_path = \"./documents\"\n",
        "documents = load_documents(folder_path)\n",
        "vectorstore = create_vector_store(documents)\n",
        "\n",
        "print(f\"âœ“ Loaded {len(documents)} documents and created embeddings\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e0f04ed1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e0f04ed1",
        "outputId": "7681dda5-a685-461c-b12b-79093d05dd93"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "â“ Question: Who created Python?\n",
            "âœ… Answer: Python was created by Guido van Rossum in 1991.\n",
            "\n",
            "ğŸ“„ Sources (3 documents):\n",
            "  1. documents/python_basics.txt\n",
            "  2. documents/india.constitution.txt\n",
            "  3. documents/ai_intro.txt\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "â“ Question: Who can vote in india?\n",
            "âœ… Answer: In India, every citizen who is 18 years of age or older has the right to vote without any discrimination. This is known as universal adult franchise.\n",
            "\n",
            "ğŸ“„ Sources (3 documents):\n",
            "  1. documents/india.constitution.txt\n",
            "  2. documents/india.constitution.txt\n",
            "  3. documents/india.constitution.txt\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "â“ Question: What is the remote work policy?\n",
            "âœ… Answer: The remote work policy allows employees to work remotely up to 3 days per week. Core hours are set from 10 AM to 3 PM local time, and all team meetings must be scheduled during these core hours. Employees are required to use Slack for daily communication and must submit their timesheets every Friday by 5 PM. The company provides a laptop and monitor for remote work, along with an internet stipend of $50 per month. For any questions regarding this policy, employees should contact HR. The policy is effective from January 2024.\n",
            "\n",
            "ğŸ“„ Sources (3 documents):\n",
            "  1. documents/company_policy.txt\n",
            "  2. documents/india.constitution.txt\n",
            "  3. documents/product_info.txt\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "â“ Question: What is machine learning?\n",
            "âœ… Answer: Machine learning is a subset of artificial intelligence (AI) that involves the use of algorithms and statistical models to enable machines to improve their performance on a specific task through experience, without being explicitly programmed. It allows systems to learn from data, identify patterns, and make decisions or predictions based on that data.\n",
            "\n",
            "ğŸ“„ Sources (3 documents):\n",
            "  1. documents/ai_intro.txt\n",
            "  2. documents/python_basics.txt\n",
            "  3. documents/product_info.txt\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# Query the documents\n",
        "def ask(question):\n",
        "    answer, sources = query_documents(vectorstore, question)\n",
        "    print(f\"\\nâ“ Question: {question}\")\n",
        "    print(f\"âœ… Answer: {answer}\")\n",
        "    print(f\"\\nğŸ“„ Sources ({len(sources)} documents):\")\n",
        "    for i, doc in enumerate(sources, 1):\n",
        "        print(f\"  {i}. {doc.metadata.get('source', 'Unknown')}\")\n",
        "    print(\"-\" * 80)\n",
        "\n",
        "# Test queries\n",
        "ask(\"Who created Python?\")\n",
        "ask(\"Who can vote in india?\")\n",
        "ask(\"What is the remote work policy?\")\n",
        "ask(\"What is machine learning?\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0eef4479",
      "metadata": {
        "id": "0eef4479"
      },
      "source": [
        "# Step 2: Query the documents\n",
        "query = \"What is the main topic of the documents?\"\n",
        "\n",
        "# Load vector store (if already created)\n",
        "# vectorstore = load_vector_store(\"faiss_index\")\n",
        "\n",
        "# Get answer\n",
        "answer, sources = query_documents(vectorstore, query)\n",
        "\n",
        "print(\"Answer:\", answer)\n",
        "print(\"\\nSources:\")\n",
        "for i, doc in enumerate(sources):\n",
        "    print(f\"{i+1}. {doc.metadata.get('source', 'Unknown')}\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.14.2"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}